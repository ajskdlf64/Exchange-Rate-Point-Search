{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기본 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "# 데이터 전처리에 필요한 라이브러리\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 모델에 필요한 라이브러리\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras  import regularizers\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET1 데이터 : 2018년 2월 ~ 2019년 2월\n",
    "# 환율 미국 달러 가격만 표시되어 있음.\n",
    "set1 = pd.read_csv('../data/set01.csv')\n",
    "set1 = set1.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>1069.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>1072.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>1076.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>1089.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>1094.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>1124.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>1125.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>1120.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>1118.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1117.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rate\n",
       "Date              \n",
       "2018-02-01  1069.6\n",
       "2018-02-02  1072.5\n",
       "2018-02-05  1076.7\n",
       "2018-02-06  1089.8\n",
       "2018-02-07  1094.3\n",
       "...            ...\n",
       "2019-02-22  1124.4\n",
       "2019-02-25  1125.7\n",
       "2019-02-26  1120.8\n",
       "2019-02-27  1118.3\n",
       "2019-02-28  1117.8\n",
       "\n",
       "[262 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shift Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과거 날짜 지정\n",
    "past_days = 5\n",
    "\n",
    "# 최근 5일까지의 과거 데이터를 생성\n",
    "for step in range(1,past_days+1):\n",
    "    set1['shift_{}'.format(step)] = set1['Rate'].shift(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>shift_1</th>\n",
       "      <th>shift_2</th>\n",
       "      <th>shift_3</th>\n",
       "      <th>shift_4</th>\n",
       "      <th>shift_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>1069.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>1072.5</td>\n",
       "      <td>1069.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>1076.7</td>\n",
       "      <td>1072.5</td>\n",
       "      <td>1069.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>1089.8</td>\n",
       "      <td>1076.7</td>\n",
       "      <td>1072.5</td>\n",
       "      <td>1069.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>1094.3</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1076.7</td>\n",
       "      <td>1072.5</td>\n",
       "      <td>1069.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>1127.7</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>1127.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>1120.8</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1124.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>1118.3</td>\n",
       "      <td>1120.8</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1117.8</td>\n",
       "      <td>1118.3</td>\n",
       "      <td>1120.8</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rate  shift_1  shift_2  shift_3  shift_4  shift_5\n",
       "Date                                                           \n",
       "2018-02-01  1069.6      NaN      NaN      NaN      NaN      NaN\n",
       "2018-02-02  1072.5   1069.6      NaN      NaN      NaN      NaN\n",
       "2018-02-05  1076.7   1072.5   1069.6      NaN      NaN      NaN\n",
       "2018-02-06  1089.8   1076.7   1072.5   1069.6      NaN      NaN\n",
       "2018-02-07  1094.3   1089.8   1076.7   1072.5   1069.6      NaN\n",
       "...            ...      ...      ...      ...      ...      ...\n",
       "2019-02-22  1124.4   1122.6   1127.5   1124.7   1127.7   1125.0\n",
       "2019-02-25  1125.7   1124.4   1122.6   1127.5   1124.7   1127.7\n",
       "2019-02-26  1120.8   1125.7   1124.4   1122.6   1127.5   1124.7\n",
       "2019-02-27  1118.3   1120.8   1125.7   1124.4   1122.6   1127.5\n",
       "2019-02-28  1117.8   1118.3   1120.8   1125.7   1124.4   1122.6\n",
       "\n",
       "[262 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 결측값 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>shift_1</th>\n",
       "      <th>shift_2</th>\n",
       "      <th>shift_3</th>\n",
       "      <th>shift_4</th>\n",
       "      <th>shift_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>1083.3</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1076.7</td>\n",
       "      <td>1072.5</td>\n",
       "      <td>1069.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>1087.8</td>\n",
       "      <td>1083.3</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1076.7</td>\n",
       "      <td>1072.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>1092.7</td>\n",
       "      <td>1087.8</td>\n",
       "      <td>1083.3</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1076.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-13</th>\n",
       "      <td>1083.4</td>\n",
       "      <td>1092.7</td>\n",
       "      <td>1087.8</td>\n",
       "      <td>1083.3</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1089.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-14</th>\n",
       "      <td>1082.8</td>\n",
       "      <td>1083.4</td>\n",
       "      <td>1092.7</td>\n",
       "      <td>1087.8</td>\n",
       "      <td>1083.3</td>\n",
       "      <td>1094.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>1127.7</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>1127.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>1120.8</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1124.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>1118.3</td>\n",
       "      <td>1120.8</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1117.8</td>\n",
       "      <td>1118.3</td>\n",
       "      <td>1120.8</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1122.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rate  shift_1  shift_2  shift_3  shift_4  shift_5\n",
       "Date                                                           \n",
       "2018-02-08  1083.3   1094.3   1089.8   1076.7   1072.5   1069.6\n",
       "2018-02-09  1087.8   1083.3   1094.3   1089.8   1076.7   1072.5\n",
       "2018-02-12  1092.7   1087.8   1083.3   1094.3   1089.8   1076.7\n",
       "2018-02-13  1083.4   1092.7   1087.8   1083.3   1094.3   1089.8\n",
       "2018-02-14  1082.8   1083.4   1092.7   1087.8   1083.3   1094.3\n",
       "...            ...      ...      ...      ...      ...      ...\n",
       "2019-02-22  1124.4   1122.6   1127.5   1124.7   1127.7   1125.0\n",
       "2019-02-25  1125.7   1124.4   1122.6   1127.5   1124.7   1127.7\n",
       "2019-02-26  1120.8   1125.7   1124.4   1122.6   1127.5   1124.7\n",
       "2019-02-27  1118.3   1120.8   1125.7   1124.4   1122.6   1127.5\n",
       "2019-02-28  1117.8   1118.3   1120.8   1125.7   1124.4   1122.6\n",
       "\n",
       "[257 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞의 5일은 과거데이터가 없으므로 결측값으로 판단하고 행 제거.\n",
    "set1 = set1.dropna()\n",
    "set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Shift 순서 뒤집기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>shift_5</th>\n",
       "      <th>shift_4</th>\n",
       "      <th>shift_3</th>\n",
       "      <th>shift_2</th>\n",
       "      <th>shift_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>1083.3</td>\n",
       "      <td>1069.6</td>\n",
       "      <td>1072.5</td>\n",
       "      <td>1076.7</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1094.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>1087.8</td>\n",
       "      <td>1072.5</td>\n",
       "      <td>1076.7</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1083.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>1092.7</td>\n",
       "      <td>1076.7</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1083.3</td>\n",
       "      <td>1087.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-13</th>\n",
       "      <td>1083.4</td>\n",
       "      <td>1089.8</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1083.3</td>\n",
       "      <td>1087.8</td>\n",
       "      <td>1092.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-14</th>\n",
       "      <td>1082.8</td>\n",
       "      <td>1094.3</td>\n",
       "      <td>1083.3</td>\n",
       "      <td>1087.8</td>\n",
       "      <td>1092.7</td>\n",
       "      <td>1083.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>1124.4</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1127.7</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1122.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>1125.7</td>\n",
       "      <td>1127.7</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1124.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>1120.8</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1125.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>1118.3</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1120.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1117.8</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>1120.8</td>\n",
       "      <td>1118.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rate  shift_5  shift_4  shift_3  shift_2  shift_1\n",
       "Date                                                           \n",
       "2018-02-08  1083.3   1069.6   1072.5   1076.7   1089.8   1094.3\n",
       "2018-02-09  1087.8   1072.5   1076.7   1089.8   1094.3   1083.3\n",
       "2018-02-12  1092.7   1076.7   1089.8   1094.3   1083.3   1087.8\n",
       "2018-02-13  1083.4   1089.8   1094.3   1083.3   1087.8   1092.7\n",
       "2018-02-14  1082.8   1094.3   1083.3   1087.8   1092.7   1083.4\n",
       "...            ...      ...      ...      ...      ...      ...\n",
       "2019-02-22  1124.4   1125.0   1127.7   1124.7   1127.5   1122.6\n",
       "2019-02-25  1125.7   1127.7   1124.7   1127.5   1122.6   1124.4\n",
       "2019-02-26  1120.8   1124.7   1127.5   1122.6   1124.4   1125.7\n",
       "2019-02-27  1118.3   1127.5   1122.6   1124.4   1125.7   1120.8\n",
       "2019-02-28  1117.8   1122.6   1124.4   1125.7   1120.8   1118.3\n",
       "\n",
       "[257 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = set1[['Rate', 'shift_5', 'shift_4', 'shift_3', 'shift_2', 'shift_1']]\n",
    "set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train Valid Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018년 2월 ~ 2019년 1월을 Train, 2019년 2월을 Test.\n",
    "# USD를 Target, 나머지 Shift를 Input으로 지정.\n",
    "\n",
    "# Train Data\n",
    "train_data = set1[:'2019-01-31'][set1.columns[1:]]\n",
    "train_targets = set1[:'2019-01-31'][set1.columns[0]]\n",
    "\n",
    "# Test Data\n",
    "test_data = set1['2019-02-01':][set1.columns[1:]]\n",
    "test_targets = set1['2019-02-01':][set1.columns[0]]\n",
    "\n",
    "# Reshape to Numpy Array : 4개의 데이터프레임을 모두 Numpy 배열로 변경.\n",
    "train_data = np.array(train_data)\n",
    "train_targets = np.array(train_targets)\n",
    "test_data = np.array(test_data)\n",
    "test_targets = np.array(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1083.3, 1087.8, 1092.7, 1083.4, 1082.8, 1079.9, 1068. , 1070.3,\n",
       "       1075.3, 1082.9, 1078.5, 1073.7, 1071. , 1081.9, 1081.3, 1080.5,\n",
       "       1075.4, 1068.7, 1068.4, 1069.2, 1064.3, 1065.8, 1065.8, 1065.8,\n",
       "       1069.6, 1071.2, 1071. , 1071.4, 1069.2, 1080.8, 1081.2, 1072.2,\n",
       "       1069.4, 1066.5, 1064.4, 1058.1, 1057.8, 1057.6, 1059.5, 1066. ,\n",
       "       1067.5, 1067.7, 1066.4, 1068.7, 1070. , 1073.1, 1068.4, 1066.5,\n",
       "       1063.5, 1067.3, 1068.9, 1076.9, 1078.7, 1079.7, 1076.2, 1067.5,\n",
       "       1074.9, 1076.5, 1076.7, 1078.2, 1081.3, 1075.3, 1068.6, 1066.6,\n",
       "       1072.6, 1078.7, 1079.3, 1080. , 1083.8, 1078.8, 1079.7, 1078.7,\n",
       "       1073.2, 1076.1, 1081.3, 1076.4, 1076. , 1070.9, 1069.6, 1067.9,\n",
       "       1073.2, 1073.5, 1075.1, 1082.5, 1091.4, 1104.4, 1105.5, 1108. ,\n",
       "       1109. , 1108.9, 1116.1, 1115.2, 1117.9, 1121.7, 1117.2, 1117.4,\n",
       "       1121.1, 1115.3, 1118.4, 1117.8, 1112.3, 1113.8, 1120.8, 1127.8,\n",
       "       1123.4, 1128.7, 1125.2, 1128.9, 1131.2, 1134.8, 1128.5, 1135.2,\n",
       "       1127.5, 1119.6, 1120. , 1116.7, 1117.9, 1119.3, 1122.6, 1128.1,\n",
       "       1123.5, 1125.7, 1118.8, 1117.9, 1126.3, 1133.7, 1132.1, 1130.7,\n",
       "       1125.6, 1121.7, 1118.2, 1118.7, 1120.8, 1121.8, 1114.3, 1110. ,\n",
       "       1108.8, 1108.8, 1113.3, 1113.5, 1114.2, 1117.6, 1121.2, 1123.1,\n",
       "       1128.1, 1126.8, 1127.3, 1121.2, 1119.2, 1126.2, 1126.3, 1123. ,\n",
       "       1119.9, 1116.6, 1112.7, 1110.2, 1110.9, 1116.4, 1128.3, 1130.7,\n",
       "       1131.7, 1132.5, 1142.5, 1133.3, 1133.4, 1128.1, 1125. , 1132.6,\n",
       "       1134.3, 1130.9, 1135.8, 1132.2, 1138.5, 1140.6, 1138.6, 1140.6,\n",
       "       1139.2, 1138.8, 1125.5, 1122.7, 1122.5, 1120.9, 1118.4, 1125.7,\n",
       "       1132. , 1135.7, 1132.4, 1130.3, 1128.7, 1127.4, 1127.5, 1131.3,\n",
       "       1129. , 1130.5, 1129.9, 1129.7, 1128.9, 1121.8, 1120.3, 1113.7,\n",
       "       1109.8, 1113.6, 1117.8, 1118.2, 1124.7, 1129.4, 1127.6, 1124. ,\n",
       "       1129.2, 1131.6, 1129.9, 1125.1, 1128.9, 1123.9, 1125.2, 1125.6,\n",
       "       1121.3, 1118.1, 1118.1, 1119. , 1127.5, 1125.2, 1118. , 1121.7,\n",
       "       1121.6, 1118.9, 1117.6, 1121.4, 1120.1, 1122. , 1121.4, 1121.3,\n",
       "       1126.5, 1130.2, 1128.2, 1128. , 1125.1, 1116.9, 1118.1, 1117.2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1111.6, 1116.8, 1123.4, 1124.5, 1124.5, 1124.6, 1121.7, 1125. ,\n",
       "       1127.7, 1124.7, 1127.5, 1122.6, 1124.4, 1125.7, 1120.8, 1118.3,\n",
       "       1117.8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input에 대해서만 정규화 진행.\n",
    "# 평균이 0, 표준편차가 1인 정규분포로 데이터를 변경.\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "# 과적합을 막기위해서 Train의 정보를 이용하여, Test에 적용한다.\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 개수가 그렇게 많지 않으므로, 모델을 깊게 생성하지는 않는다.\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # 1st Layer\n",
    "    model.add(layers.Dense(1000, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),\n",
    "                           activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    # 2nd Layer\n",
    "    model.add(layers.Dense(1000, kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    # Result\n",
    "    model.add(layers.Dense(1))\n",
    "    # Model Compile\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "240/240 [==============================] - 4s 16ms/step - loss: 1222236.3750 - mean_absolute_error: 1105.2465\n",
      "Epoch 2/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 1207450.0833 - mean_absolute_error: 1098.5019\n",
      "Epoch 3/1000\n",
      "240/240 [==============================] - 0s 44us/step - loss: 1184565.4375 - mean_absolute_error: 1087.9730\n",
      "Epoch 4/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 1154906.6667 - mean_absolute_error: 1074.1505\n",
      "Epoch 5/1000\n",
      "240/240 [==============================] - 0s 46us/step - loss: 1117929.4375 - mean_absolute_error: 1056.6571\n",
      "Epoch 6/1000\n",
      "240/240 [==============================] - 0s 45us/step - loss: 1078105.9583 - mean_absolute_error: 1037.4641\n",
      "Epoch 7/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 1032048.2500 - mean_absolute_error: 1014.7164\n",
      "Epoch 8/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 983376.2292 - mean_absolute_error: 990.0506\n",
      "Epoch 9/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 929617.7396 - mean_absolute_error: 962.0089\n",
      "Epoch 10/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 872978.3750 - mean_absolute_error: 931.6087\n",
      "Epoch 11/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 815574.6042 - mean_absolute_error: 899.5871\n",
      "Epoch 12/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 751928.7604 - mean_absolute_error: 862.4480\n",
      "Epoch 13/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 690569.4271 - mean_absolute_error: 824.8126\n",
      "Epoch 14/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 630935.9896 - mean_absolute_error: 786.4511\n",
      "Epoch 15/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 569911.2500 - mean_absolute_error: 744.6825\n",
      "Epoch 16/1000\n",
      "240/240 [==============================] - 0s 46us/step - loss: 506842.6146 - mean_absolute_error: 698.5538\n",
      "Epoch 17/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 453720.6094 - mean_absolute_error: 657.8966\n",
      "Epoch 18/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 397741.5000 - mean_absolute_error: 610.3924\n",
      "Epoch 19/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 349958.5156 - mean_absolute_error: 567.1768\n",
      "Epoch 20/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 301107.0990 - mean_absolute_error: 517.9846\n",
      "Epoch 21/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 256965.4375 - mean_absolute_error: 469.3955\n",
      "Epoch 22/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 220106.0573 - mean_absolute_error: 424.1641\n",
      "Epoch 23/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 191862.7786 - mean_absolute_error: 383.9305\n",
      "Epoch 24/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 166185.4505 - mean_absolute_error: 350.3663\n",
      "Epoch 25/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 143325.9779 - mean_absolute_error: 315.6747\n",
      "Epoch 26/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 126192.9948 - mean_absolute_error: 294.4676\n",
      "Epoch 27/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 110825.0091 - mean_absolute_error: 264.9979\n",
      "Epoch 28/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 97109.1979 - mean_absolute_error: 248.1515\n",
      "Epoch 29/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 92138.0000 - mean_absolute_error: 238.8346\n",
      "Epoch 30/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 86996.8066 - mean_absolute_error: 230.8509\n",
      "Epoch 31/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 82989.3783 - mean_absolute_error: 227.7725\n",
      "Epoch 32/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 84073.4062 - mean_absolute_error: 229.0944\n",
      "Epoch 33/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 84427.9948 - mean_absolute_error: 227.2027\n",
      "Epoch 34/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 80971.3594 - mean_absolute_error: 226.9724\n",
      "Epoch 35/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 75966.6081 - mean_absolute_error: 214.7612\n",
      "Epoch 36/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 79006.1934 - mean_absolute_error: 221.3525\n",
      "Epoch 37/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 77682.4401 - mean_absolute_error: 218.6519\n",
      "Epoch 38/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 79081.9049 - mean_absolute_error: 220.2774\n",
      "Epoch 39/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 77358.1458 - mean_absolute_error: 218.8640\n",
      "Epoch 40/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 73095.4948 - mean_absolute_error: 213.8651\n",
      "Epoch 41/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 74551.2122 - mean_absolute_error: 215.7805\n",
      "Epoch 42/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 74685.2760 - mean_absolute_error: 218.0844\n",
      "Epoch 43/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 75180.9225 - mean_absolute_error: 216.6492\n",
      "Epoch 44/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 71240.1836 - mean_absolute_error: 208.7685\n",
      "Epoch 45/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 73786.4818 - mean_absolute_error: 213.6899\n",
      "Epoch 46/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 74182.3685 - mean_absolute_error: 212.6454\n",
      "Epoch 47/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 74342.5026 - mean_absolute_error: 214.0136\n",
      "Epoch 48/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 67974.6178 - mean_absolute_error: 203.6827\n",
      "Epoch 49/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 69201.7760 - mean_absolute_error: 204.0601\n",
      "Epoch 50/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 69604.8099 - mean_absolute_error: 212.2537\n",
      "Epoch 51/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 70448.2643 - mean_absolute_error: 210.3165\n",
      "Epoch 52/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 71280.6693 - mean_absolute_error: 210.1364\n",
      "Epoch 53/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 66423.1016 - mean_absolute_error: 203.8048\n",
      "Epoch 54/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 69606.7988 - mean_absolute_error: 211.0000\n",
      "Epoch 55/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 67305.1497 - mean_absolute_error: 205.4559\n",
      "Epoch 56/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 64449.3913 - mean_absolute_error: 199.4957\n",
      "Epoch 57/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 61770.7884 - mean_absolute_error: 197.6778\n",
      "Epoch 58/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 61022.9076 - mean_absolute_error: 196.1824\n",
      "Epoch 59/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 57915.8613 - mean_absolute_error: 191.6958\n",
      "Epoch 60/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 62819.7624 - mean_absolute_error: 195.4926\n",
      "Epoch 61/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 57906.9727 - mean_absolute_error: 190.6035\n",
      "Epoch 62/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 55849.0007 - mean_absolute_error: 189.9199\n",
      "Epoch 63/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 55229.7760 - mean_absolute_error: 185.5058\n",
      "Epoch 64/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 53646.3405 - mean_absolute_error: 184.9765\n",
      "Epoch 65/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 56279.4453 - mean_absolute_error: 187.6048\n",
      "Epoch 66/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 58595.1947 - mean_absolute_error: 194.2667\n",
      "Epoch 67/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 49899.2168 - mean_absolute_error: 181.6003\n",
      "Epoch 68/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 47484.3477 - mean_absolute_error: 175.7606\n",
      "Epoch 69/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 50695.2721 - mean_absolute_error: 180.6877\n",
      "Epoch 70/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 49319.6517 - mean_absolute_error: 176.8137\n",
      "Epoch 71/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 47482.8776 - mean_absolute_error: 177.6418\n",
      "Epoch 72/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 46440.2708 - mean_absolute_error: 171.5908\n",
      "Epoch 73/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 43498.4538 - mean_absolute_error: 167.5726\n",
      "Epoch 74/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 39871.2383 - mean_absolute_error: 161.4316\n",
      "Epoch 75/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 42149.3535 - mean_absolute_error: 159.1555\n",
      "Epoch 76/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 38124.1556 - mean_absolute_error: 157.7671\n",
      "Epoch 77/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 36702.4440 - mean_absolute_error: 154.1717\n",
      "Epoch 78/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 36237.3874 - mean_absolute_error: 155.8978\n",
      "Epoch 79/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 35755.7201 - mean_absolute_error: 154.9236\n",
      "Epoch 80/1000\n",
      "240/240 [==============================] - 0s 63us/step - loss: 32195.3255 - mean_absolute_error: 142.1983\n",
      "Epoch 81/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 37142.8672 - mean_absolute_error: 154.6111\n",
      "Epoch 82/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 32103.7868 - mean_absolute_error: 149.9958\n",
      "Epoch 83/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 31365.8975 - mean_absolute_error: 145.0438\n",
      "Epoch 84/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 30942.2236 - mean_absolute_error: 140.7439\n",
      "Epoch 85/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 27878.4606 - mean_absolute_error: 137.0245\n",
      "Epoch 86/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 27808.8594 - mean_absolute_error: 135.3223\n",
      "Epoch 87/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 25411.6393 - mean_absolute_error: 129.9323\n",
      "Epoch 88/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 22183.5387 - mean_absolute_error: 121.4811\n",
      "Epoch 89/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 22030.3483 - mean_absolute_error: 120.1937\n",
      "Epoch 90/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 22728.2350 - mean_absolute_error: 121.8938\n",
      "Epoch 91/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 21168.6702 - mean_absolute_error: 115.6033\n",
      "Epoch 92/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 18963.9396 - mean_absolute_error: 108.8265\n",
      "Epoch 93/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 19855.9222 - mean_absolute_error: 116.5547\n",
      "Epoch 94/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 18299.4782 - mean_absolute_error: 110.9292\n",
      "Epoch 95/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 16527.5449 - mean_absolute_error: 103.7191\n",
      "Epoch 96/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 13789.0036 - mean_absolute_error: 94.5242\n",
      "Epoch 97/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 15026.6447 - mean_absolute_error: 97.0518\n",
      "Epoch 98/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 15050.3390 - mean_absolute_error: 100.0466\n",
      "Epoch 99/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 14849.3496 - mean_absolute_error: 97.2816\n",
      "Epoch 100/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 13259.2894 - mean_absolute_error: 93.3821\n",
      "Epoch 101/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 12918.0669 - mean_absolute_error: 92.2116\n",
      "Epoch 102/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 12999.1536 - mean_absolute_error: 91.5286\n",
      "Epoch 103/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 11625.0073 - mean_absolute_error: 87.2619\n",
      "Epoch 104/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 10405.7109 - mean_absolute_error: 83.4663\n",
      "Epoch 105/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 8952.6706 - mean_absolute_error: 76.0348\n",
      "Epoch 106/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 10234.2056 - mean_absolute_error: 81.1758\n",
      "Epoch 107/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 9407.5086 - mean_absolute_error: 79.1066\n",
      "Epoch 108/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 8380.0002 - mean_absolute_error: 73.8050\n",
      "Epoch 109/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 9237.0365 - mean_absolute_error: 77.4231\n",
      "Epoch 110/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 7603.8158 - mean_absolute_error: 69.2211\n",
      "Epoch 111/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 8174.2048 - mean_absolute_error: 69.9219\n",
      "Epoch 112/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 8118.0760 - mean_absolute_error: 71.3691\n",
      "Epoch 113/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 8304.2279 - mean_absolute_error: 72.7572\n",
      "Epoch 114/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 7086.8714 - mean_absolute_error: 68.0572\n",
      "Epoch 115/1000\n",
      "240/240 [==============================] - 0s 60us/step - loss: 6197.3330 - mean_absolute_error: 62.8276\n",
      "Epoch 116/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 6322.5596 - mean_absolute_error: 64.0327\n",
      "Epoch 117/1000\n",
      "240/240 [==============================] - 0s 60us/step - loss: 7338.3621 - mean_absolute_error: 69.7193\n",
      "Epoch 118/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 6103.4892 - mean_absolute_error: 62.3049\n",
      "Epoch 119/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 6304.6597 - mean_absolute_error: 61.3825\n",
      "Epoch 120/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5050.6112 - mean_absolute_error: 57.1294\n",
      "Epoch 121/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 5927.1704 - mean_absolute_error: 61.3577\n",
      "Epoch 122/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 6699.0687 - mean_absolute_error: 64.5469\n",
      "Epoch 123/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 6216.4084 - mean_absolute_error: 62.3644\n",
      "Epoch 124/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 6014.5634 - mean_absolute_error: 62.7692\n",
      "Epoch 125/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 5455.3727 - mean_absolute_error: 59.3737\n",
      "Epoch 126/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 6157.2303 - mean_absolute_error: 62.5992\n",
      "Epoch 127/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4816.9357 - mean_absolute_error: 57.1122\n",
      "Epoch 128/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4760.1091 - mean_absolute_error: 55.6030\n",
      "Epoch 129/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 5033.9714 - mean_absolute_error: 54.6655\n",
      "Epoch 130/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 5657.1740 - mean_absolute_error: 59.0297\n",
      "Epoch 131/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4300.6374 - mean_absolute_error: 53.9124\n",
      "Epoch 132/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4983.0204 - mean_absolute_error: 54.6137\n",
      "Epoch 133/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4205.0933 - mean_absolute_error: 52.9099\n",
      "Epoch 134/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4317.0206 - mean_absolute_error: 50.6297\n",
      "Epoch 135/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 5145.8491 - mean_absolute_error: 57.0336\n",
      "Epoch 136/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 6190.0933 - mean_absolute_error: 64.0108\n",
      "Epoch 137/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4454.5684 - mean_absolute_error: 53.9524\n",
      "Epoch 138/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 5046.0174 - mean_absolute_error: 56.4414\n",
      "Epoch 139/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4374.9486 - mean_absolute_error: 52.2529\n",
      "Epoch 140/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4987.2193 - mean_absolute_error: 56.0202\n",
      "Epoch 141/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4119.6938 - mean_absolute_error: 49.9614\n",
      "Epoch 142/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4222.4166 - mean_absolute_error: 51.5260\n",
      "Epoch 143/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4832.9478 - mean_absolute_error: 54.8153\n",
      "Epoch 144/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4840.9504 - mean_absolute_error: 54.7563\n",
      "Epoch 145/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4891.5363 - mean_absolute_error: 55.6824\n",
      "Epoch 146/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4522.1603 - mean_absolute_error: 52.3920\n",
      "Epoch 147/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5725.6247 - mean_absolute_error: 61.2979\n",
      "Epoch 148/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3982.1811 - mean_absolute_error: 50.6117\n",
      "Epoch 149/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4204.4628 - mean_absolute_error: 51.1599\n",
      "Epoch 150/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4162.0197 - mean_absolute_error: 51.0584\n",
      "Epoch 151/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3973.0225 - mean_absolute_error: 49.6250\n",
      "Epoch 152/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3996.5806 - mean_absolute_error: 49.6383\n",
      "Epoch 153/1000\n",
      "240/240 [==============================] - 0s 60us/step - loss: 4381.8710 - mean_absolute_error: 53.6547\n",
      "Epoch 154/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4412.3500 - mean_absolute_error: 50.7666\n",
      "Epoch 155/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5051.8351 - mean_absolute_error: 57.9207\n",
      "Epoch 156/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4145.6202 - mean_absolute_error: 52.1181\n",
      "Epoch 157/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4803.8658 - mean_absolute_error: 56.0588\n",
      "Epoch 158/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4893.1762 - mean_absolute_error: 54.2704\n",
      "Epoch 159/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4030.5559 - mean_absolute_error: 48.3519\n",
      "Epoch 160/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 6210.5975 - mean_absolute_error: 62.1855\n",
      "Epoch 161/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4528.0082 - mean_absolute_error: 54.3005\n",
      "Epoch 162/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4885.6003 - mean_absolute_error: 56.9403\n",
      "Epoch 163/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3733.2477 - mean_absolute_error: 49.9715\n",
      "Epoch 164/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4739.4156 - mean_absolute_error: 53.2873\n",
      "Epoch 165/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4357.0318 - mean_absolute_error: 52.8962\n",
      "Epoch 166/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 5985.7457 - mean_absolute_error: 61.7100\n",
      "Epoch 167/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4417.5004 - mean_absolute_error: 53.2011\n",
      "Epoch 168/1000\n",
      "240/240 [==============================] - 0s 44us/step - loss: 4357.8182 - mean_absolute_error: 53.1193\n",
      "Epoch 169/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4337.7733 - mean_absolute_error: 51.1198\n",
      "Epoch 170/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4187.4186 - mean_absolute_error: 52.5430\n",
      "Epoch 171/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4579.4744 - mean_absolute_error: 51.5694\n",
      "Epoch 172/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4652.1348 - mean_absolute_error: 53.3676\n",
      "Epoch 173/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5140.9621 - mean_absolute_error: 55.5696\n",
      "Epoch 174/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4938.9837 - mean_absolute_error: 55.0040\n",
      "Epoch 175/1000\n",
      "240/240 [==============================] - 0s 46us/step - loss: 4956.4382 - mean_absolute_error: 56.5311\n",
      "Epoch 176/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4545.0305 - mean_absolute_error: 52.4081\n",
      "Epoch 177/1000\n",
      "240/240 [==============================] - 0s 46us/step - loss: 4461.9006 - mean_absolute_error: 52.7478\n",
      "Epoch 178/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4599.8790 - mean_absolute_error: 53.7453\n",
      "Epoch 179/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3969.4500 - mean_absolute_error: 48.9878\n",
      "Epoch 180/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4644.7329 - mean_absolute_error: 54.3622\n",
      "Epoch 181/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4368.4167 - mean_absolute_error: 52.7869\n",
      "Epoch 182/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 5063.5473 - mean_absolute_error: 55.4702\n",
      "Epoch 183/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4903.6907 - mean_absolute_error: 55.7552\n",
      "Epoch 184/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4396.1935 - mean_absolute_error: 54.5601\n",
      "Epoch 185/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4495.0409 - mean_absolute_error: 54.2558\n",
      "Epoch 186/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4446.2918 - mean_absolute_error: 52.7993\n",
      "Epoch 187/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4396.8994 - mean_absolute_error: 53.1422\n",
      "Epoch 188/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4270.9109 - mean_absolute_error: 51.2673\n",
      "Epoch 189/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4673.1772 - mean_absolute_error: 53.9964\n",
      "Epoch 190/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4222.9224 - mean_absolute_error: 52.2262\n",
      "Epoch 191/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 5531.9022 - mean_absolute_error: 59.1011\n",
      "Epoch 192/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4275.1853 - mean_absolute_error: 53.0330\n",
      "Epoch 193/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4364.4064 - mean_absolute_error: 52.7763\n",
      "Epoch 194/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4147.4482 - mean_absolute_error: 51.9291\n",
      "Epoch 195/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4861.0506 - mean_absolute_error: 55.7123\n",
      "Epoch 196/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3768.9219 - mean_absolute_error: 48.2975\n",
      "Epoch 197/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4129.8404 - mean_absolute_error: 51.2424\n",
      "Epoch 198/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 5363.7983 - mean_absolute_error: 59.8539\n",
      "Epoch 199/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4190.5584 - mean_absolute_error: 50.7533\n",
      "Epoch 200/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4098.7665 - mean_absolute_error: 50.6128\n",
      "Epoch 201/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4207.1165 - mean_absolute_error: 51.9184\n",
      "Epoch 202/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4594.4897 - mean_absolute_error: 54.8180\n",
      "Epoch 203/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3889.5125 - mean_absolute_error: 49.2048\n",
      "Epoch 204/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3954.5028 - mean_absolute_error: 49.7764\n",
      "Epoch 205/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4645.3674 - mean_absolute_error: 54.5852\n",
      "Epoch 206/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4549.0794 - mean_absolute_error: 53.0170\n",
      "Epoch 207/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4393.0526 - mean_absolute_error: 51.4998\n",
      "Epoch 208/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4336.3310 - mean_absolute_error: 52.8210\n",
      "Epoch 209/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 5541.2946 - mean_absolute_error: 59.6612\n",
      "Epoch 210/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3989.6488 - mean_absolute_error: 50.5889\n",
      "Epoch 211/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4377.0434 - mean_absolute_error: 53.1305\n",
      "Epoch 212/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4456.1187 - mean_absolute_error: 53.5542\n",
      "Epoch 213/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3408.7040 - mean_absolute_error: 45.9684\n",
      "Epoch 214/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3769.3204 - mean_absolute_error: 49.1593\n",
      "Epoch 215/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3997.3744 - mean_absolute_error: 48.8876\n",
      "Epoch 216/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3974.4277 - mean_absolute_error: 49.7191\n",
      "Epoch 217/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4867.2288 - mean_absolute_error: 54.9942\n",
      "Epoch 218/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4000.1978 - mean_absolute_error: 50.0504\n",
      "Epoch 219/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4792.7515 - mean_absolute_error: 52.4719\n",
      "Epoch 220/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4703.5860 - mean_absolute_error: 54.3794\n",
      "Epoch 221/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3977.8977 - mean_absolute_error: 49.1488\n",
      "Epoch 222/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 5038.7747 - mean_absolute_error: 56.0013\n",
      "Epoch 223/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4412.1385 - mean_absolute_error: 52.2255\n",
      "Epoch 224/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4347.9755 - mean_absolute_error: 53.5595\n",
      "Epoch 225/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4640.9830 - mean_absolute_error: 53.7473\n",
      "Epoch 226/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5087.3975 - mean_absolute_error: 55.4702\n",
      "Epoch 227/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3510.1809 - mean_absolute_error: 48.3050\n",
      "Epoch 228/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4232.7856 - mean_absolute_error: 51.7296\n",
      "Epoch 229/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3380.4218 - mean_absolute_error: 45.7811\n",
      "Epoch 230/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4197.8924 - mean_absolute_error: 51.5278\n",
      "Epoch 231/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4507.2649 - mean_absolute_error: 53.4820\n",
      "Epoch 232/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4207.4957 - mean_absolute_error: 52.5001\n",
      "Epoch 233/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3972.6730 - mean_absolute_error: 49.5145\n",
      "Epoch 234/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3912.2612 - mean_absolute_error: 48.8767\n",
      "Epoch 235/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4005.8497 - mean_absolute_error: 48.2931\n",
      "Epoch 236/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4335.3094 - mean_absolute_error: 52.3197\n",
      "Epoch 237/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 5294.8209 - mean_absolute_error: 57.7343\n",
      "Epoch 238/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4119.2310 - mean_absolute_error: 50.6159\n",
      "Epoch 239/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4522.8091 - mean_absolute_error: 53.6237\n",
      "Epoch 240/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3962.4932 - mean_absolute_error: 49.1829\n",
      "Epoch 241/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3944.0140 - mean_absolute_error: 51.2582\n",
      "Epoch 242/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4161.5058 - mean_absolute_error: 52.4315\n",
      "Epoch 243/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4093.0701 - mean_absolute_error: 50.3391\n",
      "Epoch 244/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4211.6578 - mean_absolute_error: 51.2876\n",
      "Epoch 245/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4232.1346 - mean_absolute_error: 51.5920\n",
      "Epoch 246/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4546.8378 - mean_absolute_error: 55.2301\n",
      "Epoch 247/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3681.6727 - mean_absolute_error: 49.4429\n",
      "Epoch 248/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4250.6551 - mean_absolute_error: 51.3742\n",
      "Epoch 249/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3698.1466 - mean_absolute_error: 48.2178\n",
      "Epoch 250/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4690.0231 - mean_absolute_error: 54.5137\n",
      "Epoch 251/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4646.3325 - mean_absolute_error: 55.3681\n",
      "Epoch 252/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 5932.7685 - mean_absolute_error: 62.1533\n",
      "Epoch 253/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4436.9801 - mean_absolute_error: 53.7681\n",
      "Epoch 254/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4067.0268 - mean_absolute_error: 51.0148\n",
      "Epoch 255/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4641.3544 - mean_absolute_error: 53.9381\n",
      "Epoch 256/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3643.4944 - mean_absolute_error: 46.5260\n",
      "Epoch 257/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4107.7819 - mean_absolute_error: 51.7428\n",
      "Epoch 258/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4436.1790 - mean_absolute_error: 53.6370\n",
      "Epoch 259/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4712.7812 - mean_absolute_error: 54.7028\n",
      "Epoch 260/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4776.1772 - mean_absolute_error: 55.5012\n",
      "Epoch 261/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4339.1171 - mean_absolute_error: 52.9230\n",
      "Epoch 262/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3928.2245 - mean_absolute_error: 49.7685\n",
      "Epoch 263/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3548.4016 - mean_absolute_error: 48.0832\n",
      "Epoch 264/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4109.7808 - mean_absolute_error: 50.9417\n",
      "Epoch 265/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 6145.0221 - mean_absolute_error: 63.5927\n",
      "Epoch 266/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4285.7878 - mean_absolute_error: 52.7264\n",
      "Epoch 267/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3884.1120 - mean_absolute_error: 49.8511\n",
      "Epoch 268/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3643.3086 - mean_absolute_error: 47.4184\n",
      "Epoch 269/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4440.0975 - mean_absolute_error: 52.7870\n",
      "Epoch 270/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4255.5616 - mean_absolute_error: 50.5508\n",
      "Epoch 271/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4111.0839 - mean_absolute_error: 49.5639\n",
      "Epoch 272/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5197.9312 - mean_absolute_error: 58.2593\n",
      "Epoch 273/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3905.1098 - mean_absolute_error: 49.4588\n",
      "Epoch 274/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4391.7307 - mean_absolute_error: 52.8174\n",
      "Epoch 275/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3288.4359 - mean_absolute_error: 44.6537\n",
      "Epoch 276/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4272.3508 - mean_absolute_error: 52.2509\n",
      "Epoch 277/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3602.5568 - mean_absolute_error: 48.3346\n",
      "Epoch 278/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4979.5241 - mean_absolute_error: 54.5869\n",
      "Epoch 279/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4676.6388 - mean_absolute_error: 53.6288\n",
      "Epoch 280/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3703.5292 - mean_absolute_error: 48.1979\n",
      "Epoch 281/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4089.8906 - mean_absolute_error: 51.2054\n",
      "Epoch 282/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4850.0039 - mean_absolute_error: 55.6014\n",
      "Epoch 283/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4121.5687 - mean_absolute_error: 50.4779\n",
      "Epoch 284/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4170.9186 - mean_absolute_error: 49.9657\n",
      "Epoch 285/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3851.7527 - mean_absolute_error: 49.4584\n",
      "Epoch 286/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3896.7713 - mean_absolute_error: 49.1899\n",
      "Epoch 287/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3786.8562 - mean_absolute_error: 49.0454\n",
      "Epoch 288/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4663.1043 - mean_absolute_error: 55.7963\n",
      "Epoch 289/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4615.2499 - mean_absolute_error: 54.8637\n",
      "Epoch 290/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4811.3833 - mean_absolute_error: 56.2296\n",
      "Epoch 291/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3539.9884 - mean_absolute_error: 45.6371\n",
      "Epoch 292/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4543.4577 - mean_absolute_error: 53.5216\n",
      "Epoch 293/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4993.1728 - mean_absolute_error: 56.4855\n",
      "Epoch 294/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3910.8622 - mean_absolute_error: 49.0236\n",
      "Epoch 295/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3809.2486 - mean_absolute_error: 48.3459\n",
      "Epoch 296/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4505.7811 - mean_absolute_error: 53.7851\n",
      "Epoch 297/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 5230.9061 - mean_absolute_error: 57.7038\n",
      "Epoch 298/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3618.9951 - mean_absolute_error: 47.3176\n",
      "Epoch 299/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4587.3843 - mean_absolute_error: 53.7232\n",
      "Epoch 300/1000\n",
      "240/240 [==============================] - 0s 61us/step - loss: 3987.2001 - mean_absolute_error: 50.3167\n",
      "Epoch 301/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3735.0172 - mean_absolute_error: 49.5131\n",
      "Epoch 302/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3735.8818 - mean_absolute_error: 49.7668\n",
      "Epoch 303/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3906.4672 - mean_absolute_error: 48.1824\n",
      "Epoch 304/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4436.5732 - mean_absolute_error: 53.4815\n",
      "Epoch 305/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4044.0375 - mean_absolute_error: 51.0711\n",
      "Epoch 306/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3782.9006 - mean_absolute_error: 50.1427\n",
      "Epoch 307/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3741.2997 - mean_absolute_error: 48.3845\n",
      "Epoch 308/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3775.0184 - mean_absolute_error: 48.6232\n",
      "Epoch 309/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4400.3251 - mean_absolute_error: 50.6522\n",
      "Epoch 310/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4253.0252 - mean_absolute_error: 52.5696\n",
      "Epoch 311/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4419.7010 - mean_absolute_error: 52.2755\n",
      "Epoch 312/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3610.4802 - mean_absolute_error: 47.8872\n",
      "Epoch 313/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3613.3645 - mean_absolute_error: 48.2150\n",
      "Epoch 314/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4544.9985 - mean_absolute_error: 54.6002\n",
      "Epoch 315/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4930.9073 - mean_absolute_error: 57.5292\n",
      "Epoch 316/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3776.6912 - mean_absolute_error: 48.5908\n",
      "Epoch 317/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4060.2448 - mean_absolute_error: 51.2297\n",
      "Epoch 318/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3776.9510 - mean_absolute_error: 49.4627\n",
      "Epoch 319/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3332.0707 - mean_absolute_error: 47.0326\n",
      "Epoch 320/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4248.5319 - mean_absolute_error: 53.0893\n",
      "Epoch 321/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 5291.0876 - mean_absolute_error: 58.9669\n",
      "Epoch 322/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4293.2316 - mean_absolute_error: 50.3883\n",
      "Epoch 323/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3624.4383 - mean_absolute_error: 46.2756\n",
      "Epoch 324/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3897.1711 - mean_absolute_error: 50.1238\n",
      "Epoch 325/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4711.2383 - mean_absolute_error: 53.1359\n",
      "Epoch 326/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3506.6261 - mean_absolute_error: 45.3310\n",
      "Epoch 327/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4822.5139 - mean_absolute_error: 57.0827\n",
      "Epoch 328/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3850.7319 - mean_absolute_error: 50.1956\n",
      "Epoch 329/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4207.5754 - mean_absolute_error: 50.3921\n",
      "Epoch 330/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3579.4169 - mean_absolute_error: 46.7274\n",
      "Epoch 331/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4202.7369 - mean_absolute_error: 51.5688\n",
      "Epoch 332/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4440.7405 - mean_absolute_error: 53.4044\n",
      "Epoch 333/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4604.1680 - mean_absolute_error: 54.1749\n",
      "Epoch 334/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4615.0891 - mean_absolute_error: 53.8522\n",
      "Epoch 335/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3463.1783 - mean_absolute_error: 46.2434\n",
      "Epoch 336/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4008.4224 - mean_absolute_error: 49.5306\n",
      "Epoch 337/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4618.1909 - mean_absolute_error: 55.5356\n",
      "Epoch 338/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3521.6591 - mean_absolute_error: 47.0318\n",
      "Epoch 339/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5250.9020 - mean_absolute_error: 59.0851\n",
      "Epoch 340/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4251.4034 - mean_absolute_error: 53.6162\n",
      "Epoch 341/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 5433.5431 - mean_absolute_error: 58.7759\n",
      "Epoch 342/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3942.5630 - mean_absolute_error: 49.4429\n",
      "Epoch 343/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4477.9979 - mean_absolute_error: 53.9105\n",
      "Epoch 344/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3532.8963 - mean_absolute_error: 47.5764\n",
      "Epoch 345/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4170.7085 - mean_absolute_error: 50.3577\n",
      "Epoch 346/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4941.5462 - mean_absolute_error: 56.1479\n",
      "Epoch 347/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3724.6641 - mean_absolute_error: 49.0987\n",
      "Epoch 348/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4425.5903 - mean_absolute_error: 53.8852\n",
      "Epoch 349/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4021.9240 - mean_absolute_error: 50.4028\n",
      "Epoch 350/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3861.8768 - mean_absolute_error: 49.9971\n",
      "Epoch 351/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4791.2544 - mean_absolute_error: 55.5975\n",
      "Epoch 352/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3439.5895 - mean_absolute_error: 47.4548\n",
      "Epoch 353/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4216.8269 - mean_absolute_error: 51.1739\n",
      "Epoch 354/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4666.7308 - mean_absolute_error: 53.8688\n",
      "Epoch 355/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4415.5118 - mean_absolute_error: 52.3122\n",
      "Epoch 356/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3852.3682 - mean_absolute_error: 51.3701\n",
      "Epoch 357/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4109.1977 - mean_absolute_error: 51.3665\n",
      "Epoch 358/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4218.9342 - mean_absolute_error: 49.8439\n",
      "Epoch 359/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4367.1624 - mean_absolute_error: 53.1295\n",
      "Epoch 360/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4342.4216 - mean_absolute_error: 52.6120\n",
      "Epoch 361/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4103.2102 - mean_absolute_error: 52.7381\n",
      "Epoch 362/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4122.1228 - mean_absolute_error: 50.7071\n",
      "Epoch 363/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4102.7859 - mean_absolute_error: 49.3980\n",
      "Epoch 364/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4518.8603 - mean_absolute_error: 55.1229\n",
      "Epoch 365/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3910.1030 - mean_absolute_error: 48.4031\n",
      "Epoch 366/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4153.5354 - mean_absolute_error: 51.7218\n",
      "Epoch 367/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4834.0948 - mean_absolute_error: 55.9751\n",
      "Epoch 368/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3880.8127 - mean_absolute_error: 47.7657\n",
      "Epoch 369/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4116.8818 - mean_absolute_error: 51.5782\n",
      "Epoch 370/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4056.4170 - mean_absolute_error: 51.0131\n",
      "Epoch 371/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4943.7389 - mean_absolute_error: 56.4616\n",
      "Epoch 372/1000\n",
      "240/240 [==============================] - 0s 61us/step - loss: 4719.5703 - mean_absolute_error: 54.2575\n",
      "Epoch 373/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3928.4685 - mean_absolute_error: 48.3737\n",
      "Epoch 374/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3853.8567 - mean_absolute_error: 49.6617\n",
      "Epoch 375/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4507.4769 - mean_absolute_error: 52.5181\n",
      "Epoch 376/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4088.7544 - mean_absolute_error: 49.4955\n",
      "Epoch 377/1000\n",
      "240/240 [==============================] - 0s 64us/step - loss: 3937.6802 - mean_absolute_error: 48.0225\n",
      "Epoch 378/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4540.2952 - mean_absolute_error: 53.4964\n",
      "Epoch 379/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 5193.3063 - mean_absolute_error: 59.8119\n",
      "Epoch 380/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4595.4062 - mean_absolute_error: 54.8783\n",
      "Epoch 381/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4853.9356 - mean_absolute_error: 57.1480\n",
      "Epoch 382/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3815.6615 - mean_absolute_error: 50.1292\n",
      "Epoch 383/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3970.6825 - mean_absolute_error: 49.1511\n",
      "Epoch 384/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4266.5057 - mean_absolute_error: 52.5958\n",
      "Epoch 385/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4250.8617 - mean_absolute_error: 50.5880\n",
      "Epoch 386/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 3134.9602 - mean_absolute_error: 44.5186\n",
      "Epoch 387/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3983.8911 - mean_absolute_error: 48.9307\n",
      "Epoch 388/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3805.7639 - mean_absolute_error: 49.7387\n",
      "Epoch 389/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3674.0215 - mean_absolute_error: 47.1288\n",
      "Epoch 390/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3823.1234 - mean_absolute_error: 49.7914\n",
      "Epoch 391/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 5076.8153 - mean_absolute_error: 57.4471\n",
      "Epoch 392/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3980.7671 - mean_absolute_error: 50.0897\n",
      "Epoch 393/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3403.6187 - mean_absolute_error: 47.4095\n",
      "Epoch 394/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3617.4471 - mean_absolute_error: 48.4307\n",
      "Epoch 395/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3893.3012 - mean_absolute_error: 50.1171\n",
      "Epoch 396/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3623.0581 - mean_absolute_error: 49.5731\n",
      "Epoch 397/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4326.1118 - mean_absolute_error: 53.6701\n",
      "Epoch 398/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3205.5361 - mean_absolute_error: 43.8622\n",
      "Epoch 399/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3399.6321 - mean_absolute_error: 45.2876\n",
      "Epoch 400/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4107.1851 - mean_absolute_error: 49.6494\n",
      "Epoch 401/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3566.1539 - mean_absolute_error: 47.2498\n",
      "Epoch 402/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4191.3784 - mean_absolute_error: 51.4176\n",
      "Epoch 403/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3565.3286 - mean_absolute_error: 47.3090\n",
      "Epoch 404/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3739.4358 - mean_absolute_error: 48.2008\n",
      "Epoch 405/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4218.6193 - mean_absolute_error: 50.4185\n",
      "Epoch 406/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3909.3906 - mean_absolute_error: 50.3765\n",
      "Epoch 407/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4358.6654 - mean_absolute_error: 53.0766\n",
      "Epoch 408/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 4852.8778 - mean_absolute_error: 56.6220\n",
      "Epoch 409/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3678.3523 - mean_absolute_error: 49.2968\n",
      "Epoch 410/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3400.4970 - mean_absolute_error: 46.8913\n",
      "Epoch 411/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4319.7852 - mean_absolute_error: 51.8130\n",
      "Epoch 412/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4100.9380 - mean_absolute_error: 50.0299\n",
      "Epoch 413/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4153.5664 - mean_absolute_error: 49.4594\n",
      "Epoch 414/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3469.6856 - mean_absolute_error: 46.6016\n",
      "Epoch 415/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3604.1282 - mean_absolute_error: 48.1125\n",
      "Epoch 416/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4032.7167 - mean_absolute_error: 49.1146\n",
      "Epoch 417/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4517.9013 - mean_absolute_error: 52.6806\n",
      "Epoch 418/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3735.5423 - mean_absolute_error: 47.5059\n",
      "Epoch 419/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3485.0634 - mean_absolute_error: 45.4995\n",
      "Epoch 420/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4021.1955 - mean_absolute_error: 50.1969\n",
      "Epoch 421/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4013.4672 - mean_absolute_error: 50.5064\n",
      "Epoch 422/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3783.8649 - mean_absolute_error: 49.4367\n",
      "Epoch 423/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3825.3786 - mean_absolute_error: 49.9198\n",
      "Epoch 424/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 3007.0966 - mean_absolute_error: 44.3209\n",
      "Epoch 425/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3687.8290 - mean_absolute_error: 47.3630\n",
      "Epoch 426/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4470.2735 - mean_absolute_error: 52.2297\n",
      "Epoch 427/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4207.5350 - mean_absolute_error: 50.9725\n",
      "Epoch 428/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3877.6836 - mean_absolute_error: 49.1559\n",
      "Epoch 429/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4165.0189 - mean_absolute_error: 51.2329\n",
      "Epoch 430/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3692.6010 - mean_absolute_error: 49.1800\n",
      "Epoch 431/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4143.9614 - mean_absolute_error: 51.8669\n",
      "Epoch 432/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4220.9091 - mean_absolute_error: 51.3471\n",
      "Epoch 433/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4521.9454 - mean_absolute_error: 53.8063\n",
      "Epoch 434/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4095.0167 - mean_absolute_error: 51.3604\n",
      "Epoch 435/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4105.0953 - mean_absolute_error: 50.5857\n",
      "Epoch 436/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5533.0174 - mean_absolute_error: 61.3989\n",
      "Epoch 437/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4396.4084 - mean_absolute_error: 52.9185\n",
      "Epoch 438/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4134.5207 - mean_absolute_error: 49.6191\n",
      "Epoch 439/1000\n",
      "240/240 [==============================] - 0s 46us/step - loss: 4000.4484 - mean_absolute_error: 50.3012\n",
      "Epoch 440/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4172.8179 - mean_absolute_error: 49.9362\n",
      "Epoch 441/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4741.3656 - mean_absolute_error: 56.0163\n",
      "Epoch 442/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3436.8746 - mean_absolute_error: 46.4630\n",
      "Epoch 443/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4576.1986 - mean_absolute_error: 54.2512\n",
      "Epoch 444/1000\n",
      "240/240 [==============================] - 0s 60us/step - loss: 3610.6170 - mean_absolute_error: 48.2335\n",
      "Epoch 445/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3375.4073 - mean_absolute_error: 45.1268\n",
      "Epoch 446/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3949.4466 - mean_absolute_error: 51.0993\n",
      "Epoch 447/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3880.9591 - mean_absolute_error: 49.2137\n",
      "Epoch 448/1000\n",
      "240/240 [==============================] - 0s 60us/step - loss: 4670.6198 - mean_absolute_error: 54.6887\n",
      "Epoch 449/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3392.9135 - mean_absolute_error: 46.9113\n",
      "Epoch 450/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3976.8588 - mean_absolute_error: 49.0493\n",
      "Epoch 451/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4259.8865 - mean_absolute_error: 51.5944\n",
      "Epoch 452/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4081.9535 - mean_absolute_error: 51.0764\n",
      "Epoch 453/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4249.8293 - mean_absolute_error: 51.2149\n",
      "Epoch 454/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3365.6299 - mean_absolute_error: 44.8369\n",
      "Epoch 455/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4382.9847 - mean_absolute_error: 53.1026\n",
      "Epoch 456/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3856.0732 - mean_absolute_error: 47.8282\n",
      "Epoch 457/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4398.4394 - mean_absolute_error: 51.6461\n",
      "Epoch 458/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3912.1613 - mean_absolute_error: 49.1295\n",
      "Epoch 459/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3710.9242 - mean_absolute_error: 48.3058\n",
      "Epoch 460/1000\n",
      "240/240 [==============================] - 0s 46us/step - loss: 3828.6452 - mean_absolute_error: 49.3848\n",
      "Epoch 461/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4145.3668 - mean_absolute_error: 49.8320\n",
      "Epoch 462/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4239.7091 - mean_absolute_error: 53.0144\n",
      "Epoch 463/1000\n",
      "240/240 [==============================] - 0s 63us/step - loss: 3321.8721 - mean_absolute_error: 45.5781\n",
      "Epoch 464/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4355.6376 - mean_absolute_error: 53.0263\n",
      "Epoch 465/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4382.3288 - mean_absolute_error: 51.9180\n",
      "Epoch 466/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3615.6942 - mean_absolute_error: 47.7203\n",
      "Epoch 467/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3776.0061 - mean_absolute_error: 48.2967\n",
      "Epoch 468/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4298.4006 - mean_absolute_error: 52.7707\n",
      "Epoch 469/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4245.3258 - mean_absolute_error: 53.0368\n",
      "Epoch 470/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4277.0634 - mean_absolute_error: 51.0672\n",
      "Epoch 471/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3978.9473 - mean_absolute_error: 50.0247\n",
      "Epoch 472/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3843.7329 - mean_absolute_error: 47.1961\n",
      "Epoch 473/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4049.6686 - mean_absolute_error: 50.4290\n",
      "Epoch 474/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4159.0791 - mean_absolute_error: 51.3584\n",
      "Epoch 475/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4184.3775 - mean_absolute_error: 50.4433\n",
      "Epoch 476/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3374.9991 - mean_absolute_error: 44.7699\n",
      "Epoch 477/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3553.9976 - mean_absolute_error: 48.1621\n",
      "Epoch 478/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4199.2102 - mean_absolute_error: 51.2154\n",
      "Epoch 479/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 5128.7884 - mean_absolute_error: 55.4234\n",
      "Epoch 480/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4057.2559 - mean_absolute_error: 51.2500\n",
      "Epoch 481/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4157.8868 - mean_absolute_error: 50.0563\n",
      "Epoch 482/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4531.5680 - mean_absolute_error: 54.4180\n",
      "Epoch 483/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4096.7351 - mean_absolute_error: 50.3806\n",
      "Epoch 484/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3849.8606 - mean_absolute_error: 50.8474\n",
      "Epoch 485/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4171.3518 - mean_absolute_error: 50.3220\n",
      "Epoch 486/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3618.1242 - mean_absolute_error: 45.9151\n",
      "Epoch 487/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3510.1573 - mean_absolute_error: 47.2747\n",
      "Epoch 488/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3655.2602 - mean_absolute_error: 47.1239\n",
      "Epoch 489/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3855.3875 - mean_absolute_error: 48.7882\n",
      "Epoch 490/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4042.0400 - mean_absolute_error: 48.1182\n",
      "Epoch 491/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3729.9360 - mean_absolute_error: 47.8923\n",
      "Epoch 492/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4023.8255 - mean_absolute_error: 51.8199\n",
      "Epoch 493/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4376.2979 - mean_absolute_error: 55.0174\n",
      "Epoch 494/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3802.0144 - mean_absolute_error: 49.8409\n",
      "Epoch 495/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4111.1034 - mean_absolute_error: 49.7879\n",
      "Epoch 496/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4195.6013 - mean_absolute_error: 51.1890\n",
      "Epoch 497/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3984.3344 - mean_absolute_error: 51.0075\n",
      "Epoch 498/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3613.9928 - mean_absolute_error: 47.8372\n",
      "Epoch 499/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3641.6257 - mean_absolute_error: 47.1184\n",
      "Epoch 500/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3495.4054 - mean_absolute_error: 46.5095\n",
      "Epoch 501/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4027.6543 - mean_absolute_error: 49.4350\n",
      "Epoch 502/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4026.5366 - mean_absolute_error: 51.0900\n",
      "Epoch 503/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4349.2464 - mean_absolute_error: 52.4664\n",
      "Epoch 504/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4258.2126 - mean_absolute_error: 51.4094\n",
      "Epoch 505/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3891.0736 - mean_absolute_error: 49.2198\n",
      "Epoch 506/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4685.7215 - mean_absolute_error: 55.3215\n",
      "Epoch 507/1000\n",
      "240/240 [==============================] - 0s 45us/step - loss: 3462.0355 - mean_absolute_error: 47.1203\n",
      "Epoch 508/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3752.3677 - mean_absolute_error: 48.7041\n",
      "Epoch 509/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4165.5671 - mean_absolute_error: 50.4471\n",
      "Epoch 510/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4401.1988 - mean_absolute_error: 51.8587\n",
      "Epoch 511/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4229.6123 - mean_absolute_error: 51.8270\n",
      "Epoch 512/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4020.6531 - mean_absolute_error: 52.2306\n",
      "Epoch 513/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4229.7369 - mean_absolute_error: 52.0802\n",
      "Epoch 514/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4760.6863 - mean_absolute_error: 54.5569\n",
      "Epoch 515/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3989.7037 - mean_absolute_error: 50.5705\n",
      "Epoch 516/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4460.5280 - mean_absolute_error: 52.0712\n",
      "Epoch 517/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4273.1266 - mean_absolute_error: 52.3470\n",
      "Epoch 518/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4522.8778 - mean_absolute_error: 53.9706\n",
      "Epoch 519/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4190.1139 - mean_absolute_error: 51.9174\n",
      "Epoch 520/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 3658.9880 - mean_absolute_error: 46.4176\n",
      "Epoch 521/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4121.5704 - mean_absolute_error: 50.1011\n",
      "Epoch 522/1000\n",
      "240/240 [==============================] - 0s 45us/step - loss: 5603.6246 - mean_absolute_error: 59.2184\n",
      "Epoch 523/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4331.1566 - mean_absolute_error: 52.9918\n",
      "Epoch 524/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4410.1169 - mean_absolute_error: 52.4299\n",
      "Epoch 525/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3816.2482 - mean_absolute_error: 50.3445\n",
      "Epoch 526/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4112.0611 - mean_absolute_error: 51.3933\n",
      "Epoch 527/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4482.6948 - mean_absolute_error: 53.4274\n",
      "Epoch 528/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4225.7352 - mean_absolute_error: 50.4380\n",
      "Epoch 529/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3816.5120 - mean_absolute_error: 50.9612\n",
      "Epoch 530/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4195.4808 - mean_absolute_error: 50.6473\n",
      "Epoch 531/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3952.5007 - mean_absolute_error: 49.6838\n",
      "Epoch 532/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4342.8552 - mean_absolute_error: 53.2796\n",
      "Epoch 533/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4150.8693 - mean_absolute_error: 51.9037\n",
      "Epoch 534/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3868.6820 - mean_absolute_error: 48.6214\n",
      "Epoch 535/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3860.2953 - mean_absolute_error: 50.0553\n",
      "Epoch 536/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3557.9562 - mean_absolute_error: 47.0088\n",
      "Epoch 537/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3537.8374 - mean_absolute_error: 47.6431\n",
      "Epoch 538/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4117.0951 - mean_absolute_error: 51.0015\n",
      "Epoch 539/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4056.7146 - mean_absolute_error: 49.8172\n",
      "Epoch 540/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3854.0933 - mean_absolute_error: 49.8828\n",
      "Epoch 541/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 5059.2559 - mean_absolute_error: 56.2504\n",
      "Epoch 542/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3843.2802 - mean_absolute_error: 47.4902\n",
      "Epoch 543/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3974.2605 - mean_absolute_error: 48.3302\n",
      "Epoch 544/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4806.0159 - mean_absolute_error: 55.6726\n",
      "Epoch 545/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3960.0535 - mean_absolute_error: 50.1750\n",
      "Epoch 546/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3358.9672 - mean_absolute_error: 46.5826\n",
      "Epoch 547/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4458.1453 - mean_absolute_error: 53.4353\n",
      "Epoch 548/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4236.9584 - mean_absolute_error: 51.8462\n",
      "Epoch 549/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4460.0159 - mean_absolute_error: 52.0423\n",
      "Epoch 550/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3264.1310 - mean_absolute_error: 44.8634\n",
      "Epoch 551/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3947.5814 - mean_absolute_error: 49.9500\n",
      "Epoch 552/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4937.0512 - mean_absolute_error: 57.5987\n",
      "Epoch 553/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3751.2503 - mean_absolute_error: 48.6381\n",
      "Epoch 554/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3694.5171 - mean_absolute_error: 48.1089\n",
      "Epoch 555/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3543.1735 - mean_absolute_error: 46.9513\n",
      "Epoch 556/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4293.3890 - mean_absolute_error: 53.3131\n",
      "Epoch 557/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3940.5800 - mean_absolute_error: 49.3646\n",
      "Epoch 558/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4525.6877 - mean_absolute_error: 52.0521\n",
      "Epoch 559/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3946.3293 - mean_absolute_error: 48.4117\n",
      "Epoch 560/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3190.6180 - mean_absolute_error: 45.5146\n",
      "Epoch 561/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3896.0273 - mean_absolute_error: 48.7835\n",
      "Epoch 562/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5125.7572 - mean_absolute_error: 55.8470\n",
      "Epoch 563/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3205.4906 - mean_absolute_error: 44.5463\n",
      "Epoch 564/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 5111.7340 - mean_absolute_error: 58.4640\n",
      "Epoch 565/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4393.7763 - mean_absolute_error: 52.8709\n",
      "Epoch 566/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3408.5984 - mean_absolute_error: 45.7920\n",
      "Epoch 567/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4162.1335 - mean_absolute_error: 51.5274\n",
      "Epoch 568/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4205.0499 - mean_absolute_error: 52.5628\n",
      "Epoch 569/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4301.4722 - mean_absolute_error: 53.1822\n",
      "Epoch 570/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3812.5771 - mean_absolute_error: 50.1573\n",
      "Epoch 571/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3641.1882 - mean_absolute_error: 48.8042\n",
      "Epoch 572/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4050.1285 - mean_absolute_error: 51.4402\n",
      "Epoch 573/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3323.7143 - mean_absolute_error: 44.5874\n",
      "Epoch 574/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3797.2679 - mean_absolute_error: 47.0047\n",
      "Epoch 575/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3504.1097 - mean_absolute_error: 47.7625\n",
      "Epoch 576/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4218.9537 - mean_absolute_error: 50.2583\n",
      "Epoch 577/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3693.1794 - mean_absolute_error: 47.1310\n",
      "Epoch 578/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3256.7953 - mean_absolute_error: 45.6477\n",
      "Epoch 579/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4163.9281 - mean_absolute_error: 51.1369\n",
      "Epoch 580/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4024.3515 - mean_absolute_error: 50.9223\n",
      "Epoch 581/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4223.6740 - mean_absolute_error: 51.4957\n",
      "Epoch 582/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3570.4535 - mean_absolute_error: 47.2822\n",
      "Epoch 583/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3978.2990 - mean_absolute_error: 50.4079\n",
      "Epoch 584/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3954.1484 - mean_absolute_error: 49.5870\n",
      "Epoch 585/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3943.9341 - mean_absolute_error: 50.3872\n",
      "Epoch 586/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3462.7851 - mean_absolute_error: 44.7805\n",
      "Epoch 587/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4281.3176 - mean_absolute_error: 52.5314\n",
      "Epoch 588/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4436.1464 - mean_absolute_error: 51.6284\n",
      "Epoch 589/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4181.9479 - mean_absolute_error: 51.6499\n",
      "Epoch 590/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4484.1908 - mean_absolute_error: 53.4397\n",
      "Epoch 591/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3996.8168 - mean_absolute_error: 51.8056\n",
      "Epoch 592/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 5026.5709 - mean_absolute_error: 56.6548\n",
      "Epoch 593/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3517.5341 - mean_absolute_error: 48.9595\n",
      "Epoch 594/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3437.6100 - mean_absolute_error: 46.7887\n",
      "Epoch 595/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3496.3828 - mean_absolute_error: 47.7964\n",
      "Epoch 596/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3404.7514 - mean_absolute_error: 46.9389\n",
      "Epoch 597/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3799.2015 - mean_absolute_error: 48.8001\n",
      "Epoch 598/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3227.1987 - mean_absolute_error: 45.1074\n",
      "Epoch 599/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3456.8923 - mean_absolute_error: 47.8410\n",
      "Epoch 600/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3496.1755 - mean_absolute_error: 46.8002\n",
      "Epoch 601/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4959.5984 - mean_absolute_error: 56.2191\n",
      "Epoch 602/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4226.3804 - mean_absolute_error: 51.9142\n",
      "Epoch 603/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3959.9296 - mean_absolute_error: 49.6088\n",
      "Epoch 604/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3611.1012 - mean_absolute_error: 47.6439\n",
      "Epoch 605/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4879.0611 - mean_absolute_error: 56.1925\n",
      "Epoch 606/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3334.5880 - mean_absolute_error: 45.4288\n",
      "Epoch 607/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3914.2149 - mean_absolute_error: 49.4642\n",
      "Epoch 608/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3267.6675 - mean_absolute_error: 45.4160\n",
      "Epoch 609/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4919.6580 - mean_absolute_error: 54.2918\n",
      "Epoch 610/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3404.5368 - mean_absolute_error: 47.3281\n",
      "Epoch 611/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4475.8885 - mean_absolute_error: 51.8758\n",
      "Epoch 612/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3257.6466 - mean_absolute_error: 45.6067\n",
      "Epoch 613/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4302.5765 - mean_absolute_error: 53.0272\n",
      "Epoch 614/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4141.7611 - mean_absolute_error: 49.4476\n",
      "Epoch 615/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4189.3659 - mean_absolute_error: 52.1016\n",
      "Epoch 616/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3286.5444 - mean_absolute_error: 45.2854\n",
      "Epoch 617/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4314.0869 - mean_absolute_error: 54.0052\n",
      "Epoch 618/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3852.7964 - mean_absolute_error: 48.6847\n",
      "Epoch 619/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4251.4906 - mean_absolute_error: 51.8079\n",
      "Epoch 620/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 5090.6104 - mean_absolute_error: 57.3179\n",
      "Epoch 621/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3517.8162 - mean_absolute_error: 48.2779\n",
      "Epoch 622/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3909.4399 - mean_absolute_error: 49.6101\n",
      "Epoch 623/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4640.2720 - mean_absolute_error: 54.9000\n",
      "Epoch 624/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3944.1591 - mean_absolute_error: 51.2275\n",
      "Epoch 625/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3819.9904 - mean_absolute_error: 49.9439\n",
      "Epoch 626/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3878.3132 - mean_absolute_error: 50.4241\n",
      "Epoch 627/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 5719.5323 - mean_absolute_error: 60.0201\n",
      "Epoch 628/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3927.8189 - mean_absolute_error: 50.2754\n",
      "Epoch 629/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4291.1844 - mean_absolute_error: 52.6640\n",
      "Epoch 630/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 3413.3305 - mean_absolute_error: 46.1519\n",
      "Epoch 631/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 4231.0005 - mean_absolute_error: 50.5867\n",
      "Epoch 632/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 3395.0453 - mean_absolute_error: 46.4133\n",
      "Epoch 633/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4292.0113 - mean_absolute_error: 54.8069\n",
      "Epoch 634/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4095.2504 - mean_absolute_error: 51.2176\n",
      "Epoch 635/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4644.2856 - mean_absolute_error: 54.3615\n",
      "Epoch 636/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4135.3883 - mean_absolute_error: 50.6931\n",
      "Epoch 637/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4776.3601 - mean_absolute_error: 54.3844\n",
      "Epoch 638/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4129.8785 - mean_absolute_error: 52.3894\n",
      "Epoch 639/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4145.2341 - mean_absolute_error: 52.4470\n",
      "Epoch 640/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3846.7592 - mean_absolute_error: 49.0398\n",
      "Epoch 641/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4868.9959 - mean_absolute_error: 54.6655\n",
      "Epoch 642/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4156.4696 - mean_absolute_error: 51.8377\n",
      "Epoch 643/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4580.7790 - mean_absolute_error: 55.0222\n",
      "Epoch 644/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3482.1725 - mean_absolute_error: 45.4709\n",
      "Epoch 645/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 3515.1149 - mean_absolute_error: 46.4794\n",
      "Epoch 646/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3545.8472 - mean_absolute_error: 47.5563\n",
      "Epoch 647/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 5146.8817 - mean_absolute_error: 56.8958\n",
      "Epoch 648/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4048.8905 - mean_absolute_error: 50.6548\n",
      "Epoch 649/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4157.0157 - mean_absolute_error: 51.0243\n",
      "Epoch 650/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3926.9613 - mean_absolute_error: 50.0148\n",
      "Epoch 651/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3397.5530 - mean_absolute_error: 46.9211\n",
      "Epoch 652/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3716.6217 - mean_absolute_error: 48.0184\n",
      "Epoch 653/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3841.1352 - mean_absolute_error: 49.4878\n",
      "Epoch 654/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4642.1631 - mean_absolute_error: 53.0645\n",
      "Epoch 655/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3637.5491 - mean_absolute_error: 48.0248\n",
      "Epoch 656/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4048.2916 - mean_absolute_error: 50.0501\n",
      "Epoch 657/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4336.5309 - mean_absolute_error: 53.7576\n",
      "Epoch 658/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3575.6351 - mean_absolute_error: 47.3384\n",
      "Epoch 659/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3845.0997 - mean_absolute_error: 48.3093\n",
      "Epoch 660/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3849.0113 - mean_absolute_error: 51.2595\n",
      "Epoch 661/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3395.2087 - mean_absolute_error: 47.6833\n",
      "Epoch 662/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3923.9363 - mean_absolute_error: 50.8766\n",
      "Epoch 663/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4724.8656 - mean_absolute_error: 54.5288\n",
      "Epoch 664/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3849.0238 - mean_absolute_error: 50.2489\n",
      "Epoch 665/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4824.5225 - mean_absolute_error: 55.2469\n",
      "Epoch 666/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5481.9776 - mean_absolute_error: 61.0947\n",
      "Epoch 667/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4027.9864 - mean_absolute_error: 49.4870\n",
      "Epoch 668/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4251.3829 - mean_absolute_error: 51.8609\n",
      "Epoch 669/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4073.5153 - mean_absolute_error: 50.1567\n",
      "Epoch 670/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3590.7734 - mean_absolute_error: 47.3589\n",
      "Epoch 671/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3401.7533 - mean_absolute_error: 45.7990\n",
      "Epoch 672/1000\n",
      "240/240 [==============================] - 0s 45us/step - loss: 3143.6989 - mean_absolute_error: 46.1412\n",
      "Epoch 673/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3911.3155 - mean_absolute_error: 50.5479\n",
      "Epoch 674/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4494.3305 - mean_absolute_error: 53.4500\n",
      "Epoch 675/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3398.1583 - mean_absolute_error: 47.0814\n",
      "Epoch 676/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4261.9003 - mean_absolute_error: 51.9272\n",
      "Epoch 677/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4479.0933 - mean_absolute_error: 53.1139\n",
      "Epoch 678/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4212.6477 - mean_absolute_error: 52.2742\n",
      "Epoch 679/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4392.7510 - mean_absolute_error: 51.6881\n",
      "Epoch 680/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4083.6438 - mean_absolute_error: 50.8606\n",
      "Epoch 681/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4043.2806 - mean_absolute_error: 50.7489\n",
      "Epoch 682/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4043.5697 - mean_absolute_error: 50.2609\n",
      "Epoch 683/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3737.2997 - mean_absolute_error: 48.3391\n",
      "Epoch 684/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3669.6640 - mean_absolute_error: 48.1922\n",
      "Epoch 685/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4059.8041 - mean_absolute_error: 49.5853\n",
      "Epoch 686/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3278.8949 - mean_absolute_error: 45.1621\n",
      "Epoch 687/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3801.9224 - mean_absolute_error: 48.7663\n",
      "Epoch 688/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 5057.7995 - mean_absolute_error: 55.2423\n",
      "Epoch 689/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4518.6981 - mean_absolute_error: 54.2211\n",
      "Epoch 690/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4055.0942 - mean_absolute_error: 50.8075\n",
      "Epoch 691/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3641.8343 - mean_absolute_error: 47.7808\n",
      "Epoch 692/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3531.7838 - mean_absolute_error: 47.3651\n",
      "Epoch 693/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3303.0418 - mean_absolute_error: 45.0358\n",
      "Epoch 694/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3931.5358 - mean_absolute_error: 50.7217\n",
      "Epoch 695/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3628.7439 - mean_absolute_error: 47.1766\n",
      "Epoch 696/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 5160.8647 - mean_absolute_error: 57.6967\n",
      "Epoch 697/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3838.6015 - mean_absolute_error: 49.7201\n",
      "Epoch 698/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4743.0011 - mean_absolute_error: 55.2996\n",
      "Epoch 699/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3800.1946 - mean_absolute_error: 48.8392\n",
      "Epoch 700/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3694.1709 - mean_absolute_error: 48.3052\n",
      "Epoch 701/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 5063.9982 - mean_absolute_error: 56.5238\n",
      "Epoch 702/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3718.4664 - mean_absolute_error: 49.1739\n",
      "Epoch 703/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4494.8627 - mean_absolute_error: 53.7835\n",
      "Epoch 704/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4186.5723 - mean_absolute_error: 51.9437\n",
      "Epoch 705/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3838.3524 - mean_absolute_error: 49.2146\n",
      "Epoch 706/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4291.4827 - mean_absolute_error: 52.3502\n",
      "Epoch 707/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4721.8344 - mean_absolute_error: 55.3652\n",
      "Epoch 708/1000\n",
      "240/240 [==============================] - 0s 45us/step - loss: 6431.9167 - mean_absolute_error: 65.3351\n",
      "Epoch 709/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4153.8779 - mean_absolute_error: 52.1609\n",
      "Epoch 710/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3365.5441 - mean_absolute_error: 46.7855\n",
      "Epoch 711/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 3568.6291 - mean_absolute_error: 47.6335\n",
      "Epoch 712/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3778.8844 - mean_absolute_error: 48.9436\n",
      "Epoch 713/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4312.7520 - mean_absolute_error: 51.5816\n",
      "Epoch 714/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4393.2761 - mean_absolute_error: 51.5045\n",
      "Epoch 715/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4459.4792 - mean_absolute_error: 53.4884\n",
      "Epoch 716/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 2953.4121 - mean_absolute_error: 43.1709\n",
      "Epoch 717/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4368.9264 - mean_absolute_error: 52.9560\n",
      "Epoch 718/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4804.9887 - mean_absolute_error: 55.4886\n",
      "Epoch 719/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4333.4605 - mean_absolute_error: 53.9052\n",
      "Epoch 720/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4248.1789 - mean_absolute_error: 51.8416\n",
      "Epoch 721/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3466.1696 - mean_absolute_error: 46.4599\n",
      "Epoch 722/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4681.1848 - mean_absolute_error: 54.9852\n",
      "Epoch 723/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3838.7740 - mean_absolute_error: 49.2837\n",
      "Epoch 724/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3347.6655 - mean_absolute_error: 45.1473\n",
      "Epoch 725/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3813.8830 - mean_absolute_error: 48.5557\n",
      "Epoch 726/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3462.3324 - mean_absolute_error: 46.4885\n",
      "Epoch 727/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3146.6093 - mean_absolute_error: 43.8357\n",
      "Epoch 728/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4199.6357 - mean_absolute_error: 52.1028\n",
      "Epoch 729/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3941.5858 - mean_absolute_error: 50.7501\n",
      "Epoch 730/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4041.9365 - mean_absolute_error: 50.4818\n",
      "Epoch 731/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3494.3182 - mean_absolute_error: 46.6103\n",
      "Epoch 732/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3602.8988 - mean_absolute_error: 47.7953\n",
      "Epoch 733/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4895.7246 - mean_absolute_error: 55.4189\n",
      "Epoch 734/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3895.2450 - mean_absolute_error: 49.0579\n",
      "Epoch 735/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3447.6454 - mean_absolute_error: 45.9637\n",
      "Epoch 736/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3773.2682 - mean_absolute_error: 48.2615\n",
      "Epoch 737/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4207.3233 - mean_absolute_error: 52.1420\n",
      "Epoch 738/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3187.9832 - mean_absolute_error: 44.8088\n",
      "Epoch 739/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4568.3614 - mean_absolute_error: 53.5995\n",
      "Epoch 740/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4178.7536 - mean_absolute_error: 50.6178\n",
      "Epoch 741/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3896.9198 - mean_absolute_error: 50.2508\n",
      "Epoch 742/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3404.5338 - mean_absolute_error: 46.2998\n",
      "Epoch 743/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 5414.6689 - mean_absolute_error: 59.1711\n",
      "Epoch 744/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3074.2536 - mean_absolute_error: 43.7232\n",
      "Epoch 745/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4229.9165 - mean_absolute_error: 52.3803\n",
      "Epoch 746/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4501.8929 - mean_absolute_error: 52.3661\n",
      "Epoch 747/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3248.1972 - mean_absolute_error: 45.0107\n",
      "Epoch 748/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3578.6100 - mean_absolute_error: 47.5853\n",
      "Epoch 749/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4080.5692 - mean_absolute_error: 50.6443\n",
      "Epoch 750/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3903.8545 - mean_absolute_error: 48.7308\n",
      "Epoch 751/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3983.6050 - mean_absolute_error: 49.7174\n",
      "Epoch 752/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4219.5899 - mean_absolute_error: 51.6428\n",
      "Epoch 753/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4013.1002 - mean_absolute_error: 50.0054\n",
      "Epoch 754/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4446.4727 - mean_absolute_error: 52.7430\n",
      "Epoch 755/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3972.4990 - mean_absolute_error: 48.1903\n",
      "Epoch 756/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3498.8920 - mean_absolute_error: 46.2066\n",
      "Epoch 757/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4393.8613 - mean_absolute_error: 53.1125\n",
      "Epoch 758/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3603.4362 - mean_absolute_error: 48.0527\n",
      "Epoch 759/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3493.4548 - mean_absolute_error: 46.6200\n",
      "Epoch 760/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3836.9043 - mean_absolute_error: 50.3175\n",
      "Epoch 761/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4372.1387 - mean_absolute_error: 51.2207\n",
      "Epoch 762/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4058.3572 - mean_absolute_error: 50.8457\n",
      "Epoch 763/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4184.3919 - mean_absolute_error: 50.8391\n",
      "Epoch 764/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3910.6917 - mean_absolute_error: 50.3388\n",
      "Epoch 765/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3678.5583 - mean_absolute_error: 48.5110\n",
      "Epoch 766/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4482.8674 - mean_absolute_error: 51.9632\n",
      "Epoch 767/1000\n",
      "240/240 [==============================] - 0s 60us/step - loss: 3903.8561 - mean_absolute_error: 49.9625\n",
      "Epoch 768/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3311.7742 - mean_absolute_error: 45.3817\n",
      "Epoch 769/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3479.4809 - mean_absolute_error: 48.0630\n",
      "Epoch 770/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4176.3985 - mean_absolute_error: 50.3388\n",
      "Epoch 771/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4581.7913 - mean_absolute_error: 53.8089\n",
      "Epoch 772/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3442.8573 - mean_absolute_error: 46.9364\n",
      "Epoch 773/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3867.7503 - mean_absolute_error: 50.9861\n",
      "Epoch 774/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4233.4851 - mean_absolute_error: 52.7335\n",
      "Epoch 775/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3554.9560 - mean_absolute_error: 46.3178\n",
      "Epoch 776/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4289.4417 - mean_absolute_error: 51.2997\n",
      "Epoch 777/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4126.9698 - mean_absolute_error: 48.8175\n",
      "Epoch 778/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3458.3223 - mean_absolute_error: 46.7211\n",
      "Epoch 779/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4098.4074 - mean_absolute_error: 51.5203\n",
      "Epoch 780/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4194.2639 - mean_absolute_error: 52.6630\n",
      "Epoch 781/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4627.9092 - mean_absolute_error: 55.7254\n",
      "Epoch 782/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3479.2270 - mean_absolute_error: 47.3636\n",
      "Epoch 783/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3679.2477 - mean_absolute_error: 48.2574\n",
      "Epoch 784/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4082.0705 - mean_absolute_error: 49.9485\n",
      "Epoch 785/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3537.9271 - mean_absolute_error: 46.4851\n",
      "Epoch 786/1000\n",
      "240/240 [==============================] - 0s 48us/step - loss: 4744.5365 - mean_absolute_error: 54.4936\n",
      "Epoch 787/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4077.7427 - mean_absolute_error: 51.3522\n",
      "Epoch 788/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3938.9730 - mean_absolute_error: 49.3093\n",
      "Epoch 789/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4224.0145 - mean_absolute_error: 52.2774\n",
      "Epoch 790/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4315.0695 - mean_absolute_error: 50.4090\n",
      "Epoch 791/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4596.6448 - mean_absolute_error: 54.8304\n",
      "Epoch 792/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4317.4176 - mean_absolute_error: 49.8942\n",
      "Epoch 793/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3970.8350 - mean_absolute_error: 50.3832\n",
      "Epoch 794/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3989.2109 - mean_absolute_error: 48.5232\n",
      "Epoch 795/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3456.1340 - mean_absolute_error: 45.4575\n",
      "Epoch 796/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3855.5458 - mean_absolute_error: 48.6045\n",
      "Epoch 797/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4010.1339 - mean_absolute_error: 49.7403\n",
      "Epoch 798/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3695.4797 - mean_absolute_error: 47.2308\n",
      "Epoch 799/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3797.8811 - mean_absolute_error: 48.5246\n",
      "Epoch 800/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4122.7531 - mean_absolute_error: 50.8315\n",
      "Epoch 801/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3760.7576 - mean_absolute_error: 47.4912\n",
      "Epoch 802/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4009.9135 - mean_absolute_error: 49.5310\n",
      "Epoch 803/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3690.3727 - mean_absolute_error: 47.7849\n",
      "Epoch 804/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4862.0929 - mean_absolute_error: 54.9098\n",
      "Epoch 805/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3833.6431 - mean_absolute_error: 50.5855\n",
      "Epoch 806/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4458.2470 - mean_absolute_error: 52.9272\n",
      "Epoch 807/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4428.0045 - mean_absolute_error: 52.8111\n",
      "Epoch 808/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4553.5868 - mean_absolute_error: 53.0340\n",
      "Epoch 809/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4097.9777 - mean_absolute_error: 50.9831\n",
      "Epoch 810/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4191.1563 - mean_absolute_error: 51.3955\n",
      "Epoch 811/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3863.9116 - mean_absolute_error: 49.4486\n",
      "Epoch 812/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4808.4057 - mean_absolute_error: 54.5357\n",
      "Epoch 813/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4083.2636 - mean_absolute_error: 52.1706\n",
      "Epoch 814/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3833.0367 - mean_absolute_error: 51.1269\n",
      "Epoch 815/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3854.5613 - mean_absolute_error: 48.7154\n",
      "Epoch 816/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3820.5374 - mean_absolute_error: 50.3940\n",
      "Epoch 817/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3975.8704 - mean_absolute_error: 48.7015\n",
      "Epoch 818/1000\n",
      "240/240 [==============================] - 0s 47us/step - loss: 3642.0603 - mean_absolute_error: 47.5007\n",
      "Epoch 819/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4375.5315 - mean_absolute_error: 52.2299\n",
      "Epoch 820/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3095.4992 - mean_absolute_error: 44.5246\n",
      "Epoch 821/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 5319.8969 - mean_absolute_error: 58.1997\n",
      "Epoch 822/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4094.1152 - mean_absolute_error: 50.5058\n",
      "Epoch 823/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3921.8706 - mean_absolute_error: 50.1516\n",
      "Epoch 824/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3065.3772 - mean_absolute_error: 44.7760\n",
      "Epoch 825/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4031.0177 - mean_absolute_error: 50.9814\n",
      "Epoch 826/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3923.9377 - mean_absolute_error: 49.1942\n",
      "Epoch 827/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 3600.2811 - mean_absolute_error: 47.6502\n",
      "Epoch 828/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4846.9117 - mean_absolute_error: 56.6872\n",
      "Epoch 829/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4109.6722 - mean_absolute_error: 50.4382\n",
      "Epoch 830/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3683.3684 - mean_absolute_error: 47.7212\n",
      "Epoch 831/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4282.1846 - mean_absolute_error: 50.9374\n",
      "Epoch 832/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4490.7255 - mean_absolute_error: 52.8859\n",
      "Epoch 833/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3702.5268 - mean_absolute_error: 48.7440\n",
      "Epoch 834/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4529.3423 - mean_absolute_error: 54.4411\n",
      "Epoch 835/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4284.5739 - mean_absolute_error: 53.0134\n",
      "Epoch 836/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3901.9651 - mean_absolute_error: 48.4963\n",
      "Epoch 837/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 5093.1895 - mean_absolute_error: 57.2936\n",
      "Epoch 838/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4741.9478 - mean_absolute_error: 56.3111\n",
      "Epoch 839/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3798.3564 - mean_absolute_error: 47.6764\n",
      "Epoch 840/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4509.0317 - mean_absolute_error: 52.6919\n",
      "Epoch 841/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3606.2189 - mean_absolute_error: 47.5602\n",
      "Epoch 842/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3420.9983 - mean_absolute_error: 46.2267\n",
      "Epoch 843/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3275.6383 - mean_absolute_error: 46.0535\n",
      "Epoch 844/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4262.8938 - mean_absolute_error: 52.3294\n",
      "Epoch 845/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3588.1340 - mean_absolute_error: 47.0527\n",
      "Epoch 846/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3340.8970 - mean_absolute_error: 45.5066\n",
      "Epoch 847/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4572.8504 - mean_absolute_error: 54.9216\n",
      "Epoch 848/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4188.3990 - mean_absolute_error: 52.8207\n",
      "Epoch 849/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3709.1897 - mean_absolute_error: 49.5795\n",
      "Epoch 850/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4092.9313 - mean_absolute_error: 50.6406\n",
      "Epoch 851/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 5012.2393 - mean_absolute_error: 58.2608\n",
      "Epoch 852/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4349.8674 - mean_absolute_error: 51.6331\n",
      "Epoch 853/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3158.7041 - mean_absolute_error: 44.0978\n",
      "Epoch 854/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4152.2099 - mean_absolute_error: 52.0445\n",
      "Epoch 855/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3970.6549 - mean_absolute_error: 49.6940\n",
      "Epoch 856/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3668.3681 - mean_absolute_error: 47.6657\n",
      "Epoch 857/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3207.3549 - mean_absolute_error: 46.0323\n",
      "Epoch 858/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3938.5133 - mean_absolute_error: 49.5417\n",
      "Epoch 859/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3928.4535 - mean_absolute_error: 49.7862\n",
      "Epoch 860/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4353.7087 - mean_absolute_error: 52.2968\n",
      "Epoch 861/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4375.8145 - mean_absolute_error: 52.3955\n",
      "Epoch 862/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3511.5891 - mean_absolute_error: 47.9130\n",
      "Epoch 863/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3971.9618 - mean_absolute_error: 49.9497\n",
      "Epoch 864/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3760.4390 - mean_absolute_error: 47.7198\n",
      "Epoch 865/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4225.4859 - mean_absolute_error: 50.9715\n",
      "Epoch 866/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3792.0949 - mean_absolute_error: 48.1882\n",
      "Epoch 867/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3747.8180 - mean_absolute_error: 48.9034\n",
      "Epoch 868/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 5532.5342 - mean_absolute_error: 59.1681\n",
      "Epoch 869/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3967.2796 - mean_absolute_error: 47.8486\n",
      "Epoch 870/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3287.0780 - mean_absolute_error: 44.9557\n",
      "Epoch 871/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3938.3481 - mean_absolute_error: 48.9038\n",
      "Epoch 872/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3803.4666 - mean_absolute_error: 48.7365\n",
      "Epoch 873/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3901.2284 - mean_absolute_error: 47.5556\n",
      "Epoch 874/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 3662.9860 - mean_absolute_error: 47.5383\n",
      "Epoch 875/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3884.1450 - mean_absolute_error: 49.5633\n",
      "Epoch 876/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4869.7756 - mean_absolute_error: 54.7074\n",
      "Epoch 877/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 4090.8438 - mean_absolute_error: 51.6478\n",
      "Epoch 878/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4697.7316 - mean_absolute_error: 55.3585\n",
      "Epoch 879/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4298.4049 - mean_absolute_error: 51.3907\n",
      "Epoch 880/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 5297.2194 - mean_absolute_error: 59.7029\n",
      "Epoch 881/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3856.2941 - mean_absolute_error: 50.1672\n",
      "Epoch 882/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4584.0648 - mean_absolute_error: 54.7963\n",
      "Epoch 883/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3764.2095 - mean_absolute_error: 49.3144\n",
      "Epoch 884/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4353.8763 - mean_absolute_error: 54.1209\n",
      "Epoch 885/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3146.1147 - mean_absolute_error: 44.7949\n",
      "Epoch 886/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3770.7801 - mean_absolute_error: 50.0679\n",
      "Epoch 887/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3135.0328 - mean_absolute_error: 42.0422\n",
      "Epoch 888/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4064.7425 - mean_absolute_error: 50.3356\n",
      "Epoch 889/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3595.3999 - mean_absolute_error: 47.1995\n",
      "Epoch 890/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3569.3560 - mean_absolute_error: 46.4586\n",
      "Epoch 891/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4000.0024 - mean_absolute_error: 49.4996\n",
      "Epoch 892/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3106.0515 - mean_absolute_error: 44.1696\n",
      "Epoch 893/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4154.0495 - mean_absolute_error: 50.8746\n",
      "Epoch 894/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3388.6779 - mean_absolute_error: 47.5985\n",
      "Epoch 895/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4441.2476 - mean_absolute_error: 51.9797\n",
      "Epoch 896/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4873.8870 - mean_absolute_error: 53.8685\n",
      "Epoch 897/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3538.6988 - mean_absolute_error: 46.1241\n",
      "Epoch 898/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3677.0226 - mean_absolute_error: 47.2237\n",
      "Epoch 899/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3531.6486 - mean_absolute_error: 47.5153\n",
      "Epoch 900/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3475.8147 - mean_absolute_error: 46.7288\n",
      "Epoch 901/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4241.9013 - mean_absolute_error: 52.9395\n",
      "Epoch 902/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4219.0685 - mean_absolute_error: 51.9952\n",
      "Epoch 903/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4290.8947 - mean_absolute_error: 52.2707\n",
      "Epoch 904/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3837.0225 - mean_absolute_error: 50.1977\n",
      "Epoch 905/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3385.9171 - mean_absolute_error: 47.5978\n",
      "Epoch 906/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3592.0880 - mean_absolute_error: 47.4513\n",
      "Epoch 907/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3623.9768 - mean_absolute_error: 48.1511\n",
      "Epoch 908/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3451.8914 - mean_absolute_error: 46.7082\n",
      "Epoch 909/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3219.7621 - mean_absolute_error: 44.5244\n",
      "Epoch 910/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3227.4657 - mean_absolute_error: 44.5634\n",
      "Epoch 911/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3461.9457 - mean_absolute_error: 46.9449\n",
      "Epoch 912/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3823.5053 - mean_absolute_error: 48.3355\n",
      "Epoch 913/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4222.3701 - mean_absolute_error: 51.7910\n",
      "Epoch 914/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4062.1006 - mean_absolute_error: 49.6419\n",
      "Epoch 915/1000\n",
      "240/240 [==============================] - 0s 50us/step - loss: 4042.0404 - mean_absolute_error: 49.8197\n",
      "Epoch 916/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4111.8985 - mean_absolute_error: 50.8337\n",
      "Epoch 917/1000\n",
      "240/240 [==============================] - 0s 60us/step - loss: 4684.8529 - mean_absolute_error: 53.9214\n",
      "Epoch 918/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4290.0738 - mean_absolute_error: 53.5366\n",
      "Epoch 919/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3985.8151 - mean_absolute_error: 50.4467\n",
      "Epoch 920/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3981.7261 - mean_absolute_error: 50.2369\n",
      "Epoch 921/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3344.0002 - mean_absolute_error: 45.5271\n",
      "Epoch 922/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3513.4304 - mean_absolute_error: 46.3707\n",
      "Epoch 923/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 5043.7679 - mean_absolute_error: 57.2975\n",
      "Epoch 924/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3884.2828 - mean_absolute_error: 50.1145\n",
      "Epoch 925/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3612.1123 - mean_absolute_error: 47.2640\n",
      "Epoch 926/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4148.9712 - mean_absolute_error: 51.5755\n",
      "Epoch 927/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4102.5191 - mean_absolute_error: 50.9072\n",
      "Epoch 928/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4222.7298 - mean_absolute_error: 53.1499\n",
      "Epoch 929/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4881.2206 - mean_absolute_error: 55.3260\n",
      "Epoch 930/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4056.1105 - mean_absolute_error: 50.0029\n",
      "Epoch 931/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4434.8752 - mean_absolute_error: 54.2908\n",
      "Epoch 932/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3279.3968 - mean_absolute_error: 45.2633\n",
      "Epoch 933/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4218.0663 - mean_absolute_error: 53.4261\n",
      "Epoch 934/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4296.3998 - mean_absolute_error: 52.7434\n",
      "Epoch 935/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4427.4826 - mean_absolute_error: 52.7360\n",
      "Epoch 936/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4242.3678 - mean_absolute_error: 52.4648\n",
      "Epoch 937/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3389.9016 - mean_absolute_error: 46.9950\n",
      "Epoch 938/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4450.2337 - mean_absolute_error: 53.2006\n",
      "Epoch 939/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3797.0149 - mean_absolute_error: 49.7007\n",
      "Epoch 940/1000\n",
      "240/240 [==============================] - 0s 49us/step - loss: 4063.1244 - mean_absolute_error: 50.5150\n",
      "Epoch 941/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3402.1149 - mean_absolute_error: 46.0369\n",
      "Epoch 942/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4575.3809 - mean_absolute_error: 55.7378\n",
      "Epoch 943/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4209.8856 - mean_absolute_error: 52.3900\n",
      "Epoch 944/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3430.1059 - mean_absolute_error: 47.0165\n",
      "Epoch 945/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 3589.7367 - mean_absolute_error: 47.4468\n",
      "Epoch 946/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3366.3354 - mean_absolute_error: 45.9003\n",
      "Epoch 947/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 3591.4188 - mean_absolute_error: 48.1786\n",
      "Epoch 948/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4114.5492 - mean_absolute_error: 51.3416\n",
      "Epoch 949/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3600.6208 - mean_absolute_error: 47.4353\n",
      "Epoch 950/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3528.9543 - mean_absolute_error: 48.1457\n",
      "Epoch 951/1000\n",
      "240/240 [==============================] - 0s 51us/step - loss: 4319.0221 - mean_absolute_error: 52.9189\n",
      "Epoch 952/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3812.0689 - mean_absolute_error: 49.5365\n",
      "Epoch 953/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3808.3689 - mean_absolute_error: 48.2328\n",
      "Epoch 954/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3708.8057 - mean_absolute_error: 47.2127\n",
      "Epoch 955/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4817.8242 - mean_absolute_error: 55.8197\n",
      "Epoch 956/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3626.7186 - mean_absolute_error: 48.3339\n",
      "Epoch 957/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 5681.5704 - mean_absolute_error: 61.5998\n",
      "Epoch 958/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3354.1767 - mean_absolute_error: 46.0199\n",
      "Epoch 959/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3379.5196 - mean_absolute_error: 44.2973\n",
      "Epoch 960/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3330.0903 - mean_absolute_error: 45.0576\n",
      "Epoch 961/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3877.9486 - mean_absolute_error: 47.3825\n",
      "Epoch 962/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3612.7718 - mean_absolute_error: 47.6343\n",
      "Epoch 963/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 4625.3945 - mean_absolute_error: 53.6506\n",
      "Epoch 964/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4139.2964 - mean_absolute_error: 49.7467\n",
      "Epoch 965/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3900.5986 - mean_absolute_error: 49.2026\n",
      "Epoch 966/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3685.7442 - mean_absolute_error: 48.5242\n",
      "Epoch 967/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4077.9353 - mean_absolute_error: 50.8372\n",
      "Epoch 968/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 3662.8165 - mean_absolute_error: 48.1942\n",
      "Epoch 969/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3741.8696 - mean_absolute_error: 48.9038\n",
      "Epoch 970/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3217.1381 - mean_absolute_error: 44.5538\n",
      "Epoch 971/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3244.3651 - mean_absolute_error: 45.3951\n",
      "Epoch 972/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4056.1254 - mean_absolute_error: 51.3841\n",
      "Epoch 973/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3796.6807 - mean_absolute_error: 49.2278\n",
      "Epoch 974/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4418.4237 - mean_absolute_error: 52.9859\n",
      "Epoch 975/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3772.2870 - mean_absolute_error: 48.6272\n",
      "Epoch 976/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3841.1236 - mean_absolute_error: 48.6082\n",
      "Epoch 977/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4005.1168 - mean_absolute_error: 49.4003\n",
      "Epoch 978/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3764.5120 - mean_absolute_error: 48.9353\n",
      "Epoch 979/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4239.6080 - mean_absolute_error: 52.9039\n",
      "Epoch 980/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3978.0531 - mean_absolute_error: 50.2595\n",
      "Epoch 981/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4228.5782 - mean_absolute_error: 49.8116\n",
      "Epoch 982/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3683.8560 - mean_absolute_error: 47.2007\n",
      "Epoch 983/1000\n",
      "240/240 [==============================] - 0s 58us/step - loss: 4924.3524 - mean_absolute_error: 55.4665\n",
      "Epoch 984/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4978.4088 - mean_absolute_error: 54.0910\n",
      "Epoch 985/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 4006.2789 - mean_absolute_error: 50.3899\n",
      "Epoch 986/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3529.6622 - mean_absolute_error: 46.4555\n",
      "Epoch 987/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3357.6828 - mean_absolute_error: 46.2310\n",
      "Epoch 988/1000\n",
      "240/240 [==============================] - 0s 59us/step - loss: 3179.3107 - mean_absolute_error: 42.7567\n",
      "Epoch 989/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 3873.0526 - mean_absolute_error: 49.2263\n",
      "Epoch 990/1000\n",
      "240/240 [==============================] - 0s 56us/step - loss: 3168.0895 - mean_absolute_error: 45.2702\n",
      "Epoch 991/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 3829.8122 - mean_absolute_error: 50.4326\n",
      "Epoch 992/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3973.0019 - mean_absolute_error: 48.2089\n",
      "Epoch 993/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4463.4137 - mean_absolute_error: 53.1399\n",
      "Epoch 994/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 4409.6945 - mean_absolute_error: 51.0038\n",
      "Epoch 995/1000\n",
      "240/240 [==============================] - 0s 55us/step - loss: 3845.7622 - mean_absolute_error: 50.1034\n",
      "Epoch 996/1000\n",
      "240/240 [==============================] - 0s 53us/step - loss: 3954.5314 - mean_absolute_error: 49.5796\n",
      "Epoch 997/1000\n",
      "240/240 [==============================] - 0s 52us/step - loss: 4240.8019 - mean_absolute_error: 52.0360\n",
      "Epoch 998/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4630.8097 - mean_absolute_error: 55.0409\n",
      "Epoch 999/1000\n",
      "240/240 [==============================] - 0s 54us/step - loss: 4163.5075 - mean_absolute_error: 51.2015\n",
      "Epoch 1000/1000\n",
      "240/240 [==============================] - 0s 57us/step - loss: 4289.4140 - mean_absolute_error: 51.9111\n",
      "17/17 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# 새롭게 컴파인된 모델을 얻습니다.\n",
    "model = build_model()\n",
    "\n",
    "# 시간측정 시작\n",
    "start = timeit.default_timer()\n",
    "\n",
    "# 전체 데이터로 훈련시킵니다.\n",
    "model.fit(train_data, train_targets, epochs=1000, batch_size=200, verbose=1)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "\n",
    "# 시간측정 종료\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mae_score = 3.057401657104492\n"
     ]
    }
   ],
   "source": [
    "# Test 점수\n",
    "print('test_mae_score = {}' .format(test_mae_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 시간 : 18.47초\n"
     ]
    }
   ],
   "source": [
    "# 모델 진행 시간\n",
    "print('진행 시간 : {:.2f}초' .format(stop - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 1일뒤 예측 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNN_Model</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>1118.211670</td>\n",
       "      <td>1111.6</td>\n",
       "      <td>-6.611670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>1111.653320</td>\n",
       "      <td>1116.8</td>\n",
       "      <td>5.146680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-08</th>\n",
       "      <td>1116.208374</td>\n",
       "      <td>1123.4</td>\n",
       "      <td>7.191626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-11</th>\n",
       "      <td>1123.924683</td>\n",
       "      <td>1124.5</td>\n",
       "      <td>0.575317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>1125.120361</td>\n",
       "      <td>1124.5</td>\n",
       "      <td>-0.620361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-13</th>\n",
       "      <td>1124.049072</td>\n",
       "      <td>1124.6</td>\n",
       "      <td>0.550928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-14</th>\n",
       "      <td>1124.782593</td>\n",
       "      <td>1121.7</td>\n",
       "      <td>-3.082593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-15</th>\n",
       "      <td>1122.508179</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>2.491821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-18</th>\n",
       "      <td>1126.383301</td>\n",
       "      <td>1127.7</td>\n",
       "      <td>1.316699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-19</th>\n",
       "      <td>1129.462524</td>\n",
       "      <td>1124.7</td>\n",
       "      <td>-4.762524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>1126.142334</td>\n",
       "      <td>1127.5</td>\n",
       "      <td>1.357666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>1128.723267</td>\n",
       "      <td>1122.6</td>\n",
       "      <td>-6.123267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>1123.691406</td>\n",
       "      <td>1124.4</td>\n",
       "      <td>0.708594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>1126.163452</td>\n",
       "      <td>1125.7</td>\n",
       "      <td>-0.463452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>1127.156616</td>\n",
       "      <td>1120.8</td>\n",
       "      <td>-6.356616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>1122.179199</td>\n",
       "      <td>1118.3</td>\n",
       "      <td>-3.879199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>1118.536743</td>\n",
       "      <td>1117.8</td>\n",
       "      <td>-0.736743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DNN_Model  Actual     Error\n",
       "Date                                     \n",
       "2019-02-01  1118.211670  1111.6 -6.611670\n",
       "2019-02-07  1111.653320  1116.8  5.146680\n",
       "2019-02-08  1116.208374  1123.4  7.191626\n",
       "2019-02-11  1123.924683  1124.5  0.575317\n",
       "2019-02-12  1125.120361  1124.5 -0.620361\n",
       "2019-02-13  1124.049072  1124.6  0.550928\n",
       "2019-02-14  1124.782593  1121.7 -3.082593\n",
       "2019-02-15  1122.508179  1125.0  2.491821\n",
       "2019-02-18  1126.383301  1127.7  1.316699\n",
       "2019-02-19  1129.462524  1124.7 -4.762524\n",
       "2019-02-20  1126.142334  1127.5  1.357666\n",
       "2019-02-21  1128.723267  1122.6 -6.123267\n",
       "2019-02-22  1123.691406  1124.4  0.708594\n",
       "2019-02-25  1126.163452  1125.7 -0.463452\n",
       "2019-02-26  1127.156616  1120.8 -6.356616\n",
       "2019-02-27  1122.179199  1118.3 -3.879199\n",
       "2019-02-28  1118.536743  1117.8 -0.736743"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['Date'] = set1['2019-02-01':].index\n",
    "result['DNN_Model'] = model.predict(test_data).reshape(-1)\n",
    "result['Actual'] = test_targets\n",
    "result['Error'] = result['Actual'] - result['DNN_Model']\n",
    "result = result.set_index('Date')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNN_Model</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DNN_Model</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.61208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <td>0.61208</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DNN_Model   Actual\n",
       "DNN_Model    1.00000  0.61208\n",
       "Actual       0.61208  1.00000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상승, 하락의 방향성만....!\n",
    "result[['DNN_Model', 'Actual']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.lineplot(data=result[result.columns[:-1]], palette=\"tab10\", linewidth=2.5)\n",
    "ax.set(xticks = result.index[0::5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Virtual Data를 생성하여 5일까지 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>1111.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>1116.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-08</th>\n",
       "      <td>1123.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-11</th>\n",
       "      <td>1124.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>1124.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-13</th>\n",
       "      <td>1124.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-14</th>\n",
       "      <td>1121.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-15</th>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-18</th>\n",
       "      <td>1127.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-19</th>\n",
       "      <td>1124.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>1127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>1122.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>1124.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-25</th>\n",
       "      <td>1125.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-26</th>\n",
       "      <td>1120.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Rate\n",
       "Date              \n",
       "2019-02-01  1111.6\n",
       "2019-02-07  1116.8\n",
       "2019-02-08  1123.4\n",
       "2019-02-11  1124.5\n",
       "2019-02-12  1124.5\n",
       "2019-02-13  1124.6\n",
       "2019-02-14  1121.7\n",
       "2019-02-15  1125.0\n",
       "2019-02-18  1127.7\n",
       "2019-02-19  1124.7\n",
       "2019-02-20  1127.5\n",
       "2019-02-21  1122.6\n",
       "2019-02-22  1124.4\n",
       "2019-02-25  1125.7\n",
       "2019-02-26  1120.8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1['2019-02-01':'2019-02-26'][['Rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-25</th>\n",
       "      <td>1128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>1125.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>1116.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-30</th>\n",
       "      <td>1118.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>1117.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1일뒤</th>\n",
       "      <td>1118.211792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2일뒤</th>\n",
       "      <td>1119.094849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3일뒤</th>\n",
       "      <td>1118.807983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4일뒤</th>\n",
       "      <td>1118.682861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5일뒤</th>\n",
       "      <td>1118.366455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Rate\n",
       "2019-01-25  1128.000000\n",
       "2019-01-28  1125.100000\n",
       "2019-01-29  1116.900000\n",
       "2019-01-30  1118.100000\n",
       "2019-01-31  1117.200000\n",
       "1일뒤         1118.211792\n",
       "2일뒤         1119.094849\n",
       "3일뒤         1118.807983\n",
       "4일뒤         1118.682861\n",
       "5일뒤         1118.366455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test에 사용할 데이터\n",
    "test = pd.read_csv('../data/set01.csv')\n",
    "test = test.set_index('Date')\n",
    "test = test['2019-01-25' : '2019-01-31']\n",
    "\n",
    "# 1일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['1일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 2일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['2일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 3일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['3일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 4일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['4일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 5일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['5일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 결과\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>1111.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-07</th>\n",
       "      <td>1116.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-08</th>\n",
       "      <td>1123.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-11</th>\n",
       "      <td>1124.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-12</th>\n",
       "      <td>1124.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1일뒤</th>\n",
       "      <td>1124.049072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2일뒤</th>\n",
       "      <td>1124.162354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3일뒤</th>\n",
       "      <td>1125.278198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4일뒤</th>\n",
       "      <td>1126.709229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5일뒤</th>\n",
       "      <td>1128.332764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Rate\n",
       "2019-02-01  1111.600000\n",
       "2019-02-07  1116.800000\n",
       "2019-02-08  1123.400000\n",
       "2019-02-11  1124.500000\n",
       "2019-02-12  1124.500000\n",
       "1일뒤         1124.049072\n",
       "2일뒤         1124.162354\n",
       "3일뒤         1125.278198\n",
       "4일뒤         1126.709229\n",
       "5일뒤         1128.332764"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test에 사용할 데이터\n",
    "test = pd.read_csv('../data/set01.csv')\n",
    "test = test.set_index('Date')\n",
    "test = test['2019-02-01' : '2019-02-12']\n",
    "\n",
    "# 1일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['1일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 2일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['2일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 3일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['3일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 4일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['4일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 5일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['5일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 결과\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-13</th>\n",
       "      <td>1124.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-14</th>\n",
       "      <td>1121.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-15</th>\n",
       "      <td>1125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-18</th>\n",
       "      <td>1127.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-19</th>\n",
       "      <td>1124.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1일뒤</th>\n",
       "      <td>1126.142334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2일뒤</th>\n",
       "      <td>1127.195190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3일뒤</th>\n",
       "      <td>1128.859741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4일뒤</th>\n",
       "      <td>1131.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5일뒤</th>\n",
       "      <td>1133.349731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Rate\n",
       "2019-02-13  1124.600000\n",
       "2019-02-14  1121.700000\n",
       "2019-02-15  1125.000000\n",
       "2019-02-18  1127.700000\n",
       "2019-02-19  1124.700000\n",
       "1일뒤         1126.142334\n",
       "2일뒤         1127.195190\n",
       "3일뒤         1128.859741\n",
       "4일뒤         1131.210938\n",
       "5일뒤         1133.349731"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test에 사용할 데이터\n",
    "test = pd.read_csv('../data/set01.csv')\n",
    "test = test.set_index('Date')\n",
    "test = test['2019-02-13' : '2019-02-19']\n",
    "\n",
    "# 1일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['1일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 2일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['2일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 3일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['3일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 4일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['4일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 5일 뒤 예측\n",
    "test_sc = (np.array(test[-5:].T) - mean) / std\n",
    "pred_df = pd.DataFrame({'Rate':model.predict(test_sc).reshape(-1)[0]}, index=['5일뒤'])\n",
    "test = test.append(pred_df)\n",
    "\n",
    "# 결과\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 추천한 날짜마다 5달러씩 매입시 가격 : 16850.0원\n"
     ]
    }
   ],
   "source": [
    "# 모델이 추천하는 매입 시점\n",
    "point = ['2019-02-12', '2019-02-19', '2019-02-26']\n",
    "model_pred = np.sum(set1.loc[point]['Rate']) * 5\n",
    "print('모델이 추천한 날짜마다 5달러씩 매입시 가격 : {}원' .format(model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "매일 1달러씩 매입시 가격 : 16845.5원\n"
     ]
    }
   ],
   "source": [
    "# 매일 1달러씩 15일간 15달러 매입\n",
    "real = np.sum(set1['2019-02-01':'2019-02-26'][['Rate']]).values[0]\n",
    "print('매일 1달러씩 매입시 가격 : {}원' .format(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손익 계산 : -4.5원 이익!!!!!, 약 -0.00027%의 이익률\n"
     ]
    }
   ],
   "source": [
    "print('손익 계산 : {}원 이익!!!!!, 약 {:.5f}%의 이익률' .format(real - model_pred, (real - model_pred)/real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론\n",
    "\n",
    " - **단순 등락여부를 맞춘다고 가정했을 때는 60% 정도의 예측 정확도를 보임.**\n",
    " \n",
    " \n",
    " - **DNN을 사용한 결과 시퀀스의 특징을 완전히 무시함. --> 값은 예측이 되는 것처럼 보이지만, 항상 5일 뒤가 가장 낮은 값을 보임.**\n",
    " \n",
    " \n",
    " - **RNN, LSTM과의 비교가 필요함.**\n",
    " \n",
    " \n",
    " - **한번에 5일까지를 예측하는 가장 좋은 방법이 뭘까....?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
