{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[7 0]\n",
      " [9 0]]\n",
      "Train Accuracy : 0.6008230452674898\n",
      "Test Accuracy : 0.4375\n",
      "\n",
      "\n",
      "DecisionTreeClassifier\n",
      "[[7 0]\n",
      " [7 2]]\n",
      "Train Accuracy : 1.0\n",
      "Test Accuracy : 0.5625\n",
      "\n",
      "\n",
      "RandomForestClassifier\n",
      "[[4 3]\n",
      " [6 3]]\n",
      "Train Accuracy : 0.6831275720164609\n",
      "Test Accuracy : 0.4375\n",
      "\n",
      "\n",
      "GradientBoostingClassifier\n",
      "[[7 0]\n",
      " [7 2]]\n",
      "Train Accuracy : 0.9382716049382716\n",
      "Test Accuracy : 0.5625\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "[[6 1]\n",
      " [4 5]]\n",
      "Train Accuracy : 0.9629629629629629\n",
      "Test Accuracy : 0.6875\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 경고 메세지 안뜨게 하기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "# Dataset Loading\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('../data/er_data.csv')\n",
    "\n",
    "# Dataset Columns\n",
    "dataset.columns = ['DATE', 'CAD', 'CHF', 'EUR', 'GBP', 'JPY(100)', 'BITCOIN', 'TETHER', 'USD']\n",
    "\n",
    "# Dataset Index\n",
    "dataset = dataset.set_index('DATE')\n",
    "\n",
    "# Train Test Split\n",
    "train = dataset['2018-02-01':'2019-01-31']\n",
    "test = dataset['2019-02-01':'2019-02-28']\n",
    "\n",
    "# Train (sliding Window)\n",
    "train['USD_1'] = train['USD'].shift(-1)\n",
    "train['Target'] = train['USD_1'] - train['USD']\n",
    "train['Target'] = train['Target'].apply(lambda x : 'UP' if x > 0 else 'DOWN')\n",
    "train = train.dropna()\n",
    "\n",
    "# Test (sliding Window)\n",
    "test['USD_1'] = test['USD'].shift(-1)\n",
    "test['Target'] = test['USD_1'] - test['USD']\n",
    "test['Target'] = test['Target'].apply(lambda x : 'UP' if x > 0 else 'DOWN')\n",
    "test = test.dropna()\n",
    "\n",
    "# Target, Input Split\n",
    "train_input = train[['CAD', \"CHF\", \"EUR\", 'GBP', 'JPY(100)', 'BITCOIN', 'TETHER']]\n",
    "train_target = train['Target']\n",
    "\n",
    "test_input = test[['CAD', \"CHF\", \"EUR\", 'GBP', 'JPY(100)', 'BITCOIN', 'TETHER']]\n",
    "test_target = test['Target']\n",
    "\n",
    "# Transform to Numpy Array\n",
    "import numpy as np\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "# Data Normalization\n",
    "mean = train_input.mean(axis=0)\n",
    "train_input -= mean\n",
    "std = train_input.std(axis=0)\n",
    "train_input /= std\n",
    "test_input -= mean\n",
    "test_input /= std\n",
    "\n",
    "# Logistic Regression\n",
    "print('Logistic Regression')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(train_input, train_target)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(train_input)\n",
    "y_true = train_target\n",
    "print('Train Accuracy :',accuracy_score(y_true, y_pred))\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print('Test Accuracy :',accuracy_score(y_true, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "# DecisionTreeClassifier\n",
    "print('DecisionTreeClassifier')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0).fit(train_input, train_target)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(train_input)\n",
    "y_true = train_target\n",
    "print('Train Accuracy :',accuracy_score(y_true, y_pred))\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print('Test Accuracy :',accuracy_score(y_true, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "# RandomForestClassifier\n",
    "print('RandomForestClassifier')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0).fit(train_input, train_target)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(train_input)\n",
    "y_true = train_target\n",
    "print('Train Accuracy :',accuracy_score(y_true, y_pred))\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print('Test Accuracy :',accuracy_score(y_true, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "print('GradientBoostingClassifier')\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(max_depth=2, random_state=0).fit(train_input, train_target)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(train_input)\n",
    "y_true = train_target\n",
    "print('Train Accuracy :',accuracy_score(y_true, y_pred))\n",
    "y_pred = clf.predict(test_input)\n",
    "y_true = test_target\n",
    "print('Test Accuracy :',accuracy_score(y_true, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "# XGBoost\n",
    "print('XGBClassifier')\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(booster='gbtree', \n",
    "                      colsample_bylevel=0.9, \n",
    "                      colsample_bytree=0.8, \n",
    "                      gamma=0, \n",
    "                      max_depth=8, \n",
    "                      min_child_weight=3, \n",
    "                      n_estimators=50, \n",
    "                      nthread=4, \n",
    "                      objective='binary:logistic', \n",
    "                      random_state=2, \n",
    "                      silent= True)\n",
    "\n",
    "model.fit(train_input,train_target, eval_set=[(train_input, train_target)], early_stopping_rounds=50,verbose=0)\n",
    "y_pred = model.predict(test_input)\n",
    "y_true = test_target\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(train_input)\n",
    "y_true = train_target\n",
    "print('Train Accuracy :',accuracy_score(y_true, y_pred))\n",
    "y_pred = model.predict(test_input)\n",
    "y_true = test_target\n",
    "print('Test Accuracy :',accuracy_score(y_true, y_pred))\n",
    "print('\\n\\n')\n",
    "\n",
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Over Sampling for SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Stacking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
